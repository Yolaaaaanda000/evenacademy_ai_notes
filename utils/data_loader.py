"""
æ•°æ®åŠ è½½å™¨ - ç”¨äºåŠ è½½é¢˜åº“å’Œå…¶ä»–æ•°æ®æ–‡ä»¶
"""

import pandas as pd
import os
import json
from typing import Dict, List, Optional


class QuestionLoader:
    """é¢˜ç›®æ•°æ®åŠ è½½å™¨"""
    
    def __init__(self):
        self.data_dir = "data"
        self.questions_dir = os.path.join(self.data_dir, "questions")
        self.cache = {}
        
    def load_csv_questions(self, filename: str) -> pd.DataFrame:
        """
        åŠ è½½CSVæ ¼å¼çš„é¢˜ç›®æ•°æ®
        
        Args:
            filename: CSVæ–‡ä»¶å
            
        Returns:
            pd.DataFrame: é¢˜ç›®æ•°æ®
        """
        filepath = os.path.join(self.questions_dir, filename)
        
        if not os.path.exists(filepath):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            return pd.DataFrame()
        
        try:
            # å°è¯•ä¸åŒçš„ç¼–ç æ ¼å¼
            encodings = ['utf-8', 'gbk', 'gb2312', 'latin1']
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(filepath, encoding=encoding)
                    print(f"âœ… æˆåŠŸåŠ è½½é¢˜ç›®æ–‡ä»¶: {filename} (ç¼–ç : {encoding})")
                    return df
                except UnicodeDecodeError:
                    continue
                except Exception as e:
                    print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥: {e}")
                    continue
            
            print(f"âŒ æ— æ³•åŠ è½½æ–‡ä»¶: {filename}")
            return pd.DataFrame()
            
        except Exception as e:
            print(f"âŒ åŠ è½½é¢˜ç›®æ–‡ä»¶å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def load_all_question_files(self) -> Dict[str, pd.DataFrame]:
        """
        åŠ è½½æ‰€æœ‰é¢˜ç›®æ–‡ä»¶
        
        Returns:
            Dict[str, pd.DataFrame]: æ–‡ä»¶ååˆ°æ•°æ®æ¡†çš„æ˜ å°„
        """
        if not os.path.exists(self.questions_dir):
            print(f"âŒ é¢˜ç›®ç›®å½•ä¸å­˜åœ¨: {self.questions_dir}")
            return {}
        
        question_files = {}
        
        for filename in os.listdir(self.questions_dir):
            if filename.endswith('.csv'):
                df = self.load_csv_questions(filename)
                if not df.empty:
                    question_files[filename] = df
        
        print(f"ğŸ“Š æ€»å…±åŠ è½½äº† {len(question_files)} ä¸ªé¢˜ç›®æ–‡ä»¶")
        return question_files
    
    def get_question_statistics(self, df: pd.DataFrame) -> Dict:
        """
        è·å–é¢˜ç›®æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            df: é¢˜ç›®æ•°æ®æ¡†
            
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        if df.empty:
            return {}
        
        stats = {
            'total_questions': len(df),
            'columns': list(df.columns),
            'missing_values': df.isnull().sum().to_dict()
        }
        
        # å¦‚æœæœ‰Topicåˆ—ï¼Œç»Ÿè®¡ä¸»é¢˜åˆ†å¸ƒ
        if 'Topic' in df.columns:
            topic_counts = df['Topic'].value_counts()
            stats['topic_distribution'] = topic_counts.head(10).to_dict()
        
        # å¦‚æœæœ‰å¹´ä»½åˆ—ï¼Œç»Ÿè®¡å¹´ä»½åˆ†å¸ƒ
        if 'å¹´ä»½' in df.columns:
            year_counts = df['å¹´ä»½'].value_counts()
            stats['year_distribution'] = year_counts.head(10).to_dict()
        
        return stats
    
    def search_questions(self, df: pd.DataFrame, keywords: List[str], 
                        search_columns: List[str] = None) -> pd.DataFrame:
        """
        åœ¨é¢˜ç›®ä¸­æœç´¢å…³é”®è¯
        
        Args:
            df: é¢˜ç›®æ•°æ®æ¡†
            keywords: æœç´¢å…³é”®è¯åˆ—è¡¨
            search_columns: æœç´¢çš„åˆ—ååˆ—è¡¨
            
        Returns:
            pd.DataFrame: åŒ¹é…çš„é¢˜ç›®
        """
        if df.empty:
            return pd.DataFrame()
        
        if search_columns is None:
            search_columns = ['é¢˜ç›®', 'Topic', 'formatted_title']
        
        # è¿‡æ»¤å­˜åœ¨çš„åˆ—
        available_columns = [col for col in search_columns if col in df.columns]
        
        if not available_columns:
            print("âŒ æ²¡æœ‰å¯æœç´¢çš„åˆ—")
            return pd.DataFrame()
        
        # åˆ›å»ºæœç´¢æ¡ä»¶
        search_conditions = []
        for keyword in keywords:
            keyword_conditions = []
            for col in available_columns:
                keyword_conditions.append(df[col].str.contains(keyword, case=False, na=False))
            search_conditions.append(pd.concat(keyword_conditions, axis=1).any(axis=1))
        
        # åˆå¹¶æ‰€æœ‰æ¡ä»¶ï¼ˆORå…³ç³»ï¼‰
        if search_conditions:
            final_condition = pd.concat(search_conditions, axis=1).any(axis=1)
            matched_df = df[final_condition]
        else:
            matched_df = pd.DataFrame()
        
        print(f"ğŸ” æœç´¢å…³é”®è¯ {keywords} æ‰¾åˆ° {len(matched_df)} é“é¢˜ç›®")
        return matched_df
    
    def filter_questions_by_topic(self, df: pd.DataFrame, topics: List[str]) -> pd.DataFrame:
        """
        æ ¹æ®ä¸»é¢˜è¿‡æ»¤é¢˜ç›®
        
        Args:
            df: é¢˜ç›®æ•°æ®æ¡†
            topics: ä¸»é¢˜åˆ—è¡¨
            
        Returns:
            pd.DataFrame: è¿‡æ»¤åçš„é¢˜ç›®
        """
        if df.empty or 'Topic' not in df.columns:
            return pd.DataFrame()
        
        # åˆ›å»ºä¸»é¢˜è¿‡æ»¤æ¡ä»¶
        topic_conditions = []
        for topic in topics:
            topic_conditions.append(df['Topic'].str.contains(topic, case=False, na=False))
        
        if topic_conditions:
            final_condition = pd.concat(topic_conditions, axis=1).any(axis=1)
            filtered_df = df[final_condition]
        else:
            filtered_df = pd.DataFrame()
        
        print(f"ğŸ“‹ æ ¹æ®ä¸»é¢˜ {topics} è¿‡æ»¤å¾—åˆ° {len(filtered_df)} é“é¢˜ç›®")
        return filtered_df
    
    def get_random_questions(self, df: pd.DataFrame, n: int = 5) -> pd.DataFrame:
        """
        éšæœºè·å–é¢˜ç›®
        
        Args:
            df: é¢˜ç›®æ•°æ®æ¡†
            n: é¢˜ç›®æ•°é‡
            
        Returns:
            pd.DataFrame: éšæœºé¢˜ç›®
        """
        if df.empty:
            return pd.DataFrame()
        
        n = min(n, len(df))
        random_df = df.sample(n=n, random_state=42)
        
        print(f"ğŸ² éšæœºè·å–äº† {len(random_df)} é“é¢˜ç›®")
        return random_df


class DataLoader:
    """é€šç”¨æ•°æ®åŠ è½½å™¨"""
    
    def __init__(self):
        self.data_dir = "data"
        self.cache = {}
    
    def load_json(self, filename: str) -> Dict:
        """
        åŠ è½½JSONæ–‡ä»¶
        
        Args:
            filename: JSONæ–‡ä»¶å
            
        Returns:
            Dict: JSONæ•°æ®
        """
        filepath = os.path.join(self.data_dir, filename)
        
        if not os.path.exists(filepath):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            return {}
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"âœ… æˆåŠŸåŠ è½½JSONæ–‡ä»¶: {filename}")
            return data
        except Exception as e:
            print(f"âŒ åŠ è½½JSONæ–‡ä»¶å¤±è´¥: {e}")
            return {}
    
    def save_json(self, data: Dict, filename: str) -> bool:
        """
        ä¿å­˜JSONæ–‡ä»¶
        
        Args:
            data: è¦ä¿å­˜çš„æ•°æ®
            filename: æ–‡ä»¶å
            
        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        filepath = os.path.join(self.data_dir, filename)
        
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æˆåŠŸä¿å­˜JSONæ–‡ä»¶: {filename}")
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜JSONæ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def list_data_files(self, extension: str = None) -> List[str]:
        """
        åˆ—å‡ºæ•°æ®æ–‡ä»¶
        
        Args:
            extension: æ–‡ä»¶æ‰©å±•åè¿‡æ»¤
            
        Returns:
            List[str]: æ–‡ä»¶ååˆ—è¡¨
        """
        if not os.path.exists(self.data_dir):
            return []
        
        files = []
        for filename in os.listdir(self.data_dir):
            if extension is None or filename.endswith(extension):
                files.append(filename)
        
        return files


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æµ‹è¯•é¢˜ç›®åŠ è½½å™¨
    loader = QuestionLoader()
    
    # åŠ è½½æ‰€æœ‰é¢˜ç›®æ–‡ä»¶
    question_files = loader.load_all_question_files()
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    for filename, df in question_files.items():
        print(f"\nğŸ“Š {filename} ç»Ÿè®¡ä¿¡æ¯:")
        stats = loader.get_question_statistics(df)
        for key, value in stats.items():
            print(f"  {key}: {value}")
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    if question_files:
        first_df = list(question_files.values())[0]
        print(f"\nğŸ” æœç´¢æµ‹è¯•:")
        search_results = loader.search_questions(first_df, ['probability', 'æ¦‚ç‡'])
        print(f"æ‰¾åˆ° {len(search_results)} é“ç›¸å…³é¢˜ç›®") 