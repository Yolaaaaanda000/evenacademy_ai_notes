import hashlib
import os
import tempfile
import whisper
import ffmpeg
import google.generativeai as genai
import json
from datetime import datetime
import re
from typing import List, Dict, Tuple, Optional
from core.summary_integrator import SummaryIntegrator  # ğŸ†• ä¼˜åŒ–1: å¯¼å…¥æ–°çš„Summaryæ•´åˆå™¨
from core.prompt_manager import PromptManager  # ğŸ†• æ·»åŠ PromptManagerå¯¼å…¥


class VideoProcessor:
    def __init__(self, api_key: str):
        """åˆå§‹åŒ–è§†é¢‘å¤„ç†å™¨"""
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.5-pro')
        self.summary_integrator = SummaryIntegrator(api_key, prompts_dir="./prompts")  # ğŸ†• ä¼˜åŒ–2: åˆå§‹åŒ–Summaryæ•´åˆå™¨

        # ğŸ†• åˆå§‹åŒ–Promptç®¡ç†å™¨
        self.prompt_manager = PromptManager("./prompts")

        # ğŸ†• ä¼˜åŒ–3: ç¼“å­˜ç›®å½•è®¾ç½®
        self.cache_dir = "./data/cache"
        os.makedirs(self.cache_dir, exist_ok=True)
        
        self.processing_log = {
            "token_count": 0,
            "segments_count": 0,
            "segments_details": [],
            "timestamp_matches": [],
            "processing_time": 0,
            "api_calls": 0,
            "transcription_length": 0,
            "content_type": "",
            "content_subtype": "",
            "confidence": 0.0
        }
            # ğŸ†• éªŒè¯å¿…éœ€çš„Promptæ–‡ä»¶
        self._validate_prompts()
    
    def _validate_prompts(self):
        """éªŒè¯å¿…éœ€çš„Promptæ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        required_prompts = {
            "video_analysis": ["lecture_title", "transcription_text"]
        }
        
        for prompt_name, required_params in required_prompts.items():
            validation = self.prompt_manager.validate_prompt(prompt_name, required_params)
            
            if not validation['exists']:
                print(f"âš ï¸ ç¼ºå°‘Promptæ–‡ä»¶: {prompt_name}.md")
                # ğŸ†• è‡ªåŠ¨åˆ›å»ºé»˜è®¤Promptæ–‡ä»¶
                self._create_default_video_analysis_prompt()
            elif not validation['valid']:
                print(f"âš ï¸ Promptæ–‡ä»¶ {prompt_name}.md ç¼ºå°‘å¿…éœ€å‚æ•°: {validation['missing_params']}")
    
    def _create_default_video_analysis_prompt(self):
        """åˆ›å»ºé»˜è®¤çš„è§†é¢‘åˆ†æPrompt"""
        default_prompt = """# è§†é¢‘å†…å®¹åˆ†æPromptæ¨¡æ¿

ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯¾ç¨‹å†…å®¹åˆ†æåŠ©æ‰‹ã€‚è¯·åˆ†æä»¥ä¸‹è§†é¢‘è½¬å½•å†…å®¹ï¼Œå¹¶å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

## åˆ†æè¦æ±‚ï¼š

### 1. å†…å®¹ç±»å‹åˆ¤æ–­
è¯·åˆ¤æ–­è§†é¢‘å†…å®¹ç±»å‹ï¼š
- **æ¦‚å¿µè®²è§£**: æ–°çŸ¥è¯†ç‚¹çš„å¼•å…¥ã€å®šä¹‰ã€åŸç†è¯´æ˜
- **é¢˜ç›®å¤ä¹ **: ä¹ é¢˜è®²è§£ã€è§£é¢˜æ­¥éª¤ã€ç­”æ¡ˆåˆ†æ
- **æ··åˆå†…å®¹**: æ—¢æœ‰æ¦‚å¿µè®²è§£åˆæœ‰é¢˜ç›®ç»ƒä¹ 

### 2. å†…å®¹åˆ‡ç‰‡è¯†åˆ«
è¯†åˆ«è§†é¢‘ä¸­çš„é‡è¦å†…å®¹ç‰‡æ®µï¼Œæ¯ä¸ªç‰‡æ®µåº”è¯¥ï¼š
- æœ‰æ˜ç¡®çš„å¼€å§‹å’Œç»“æŸ
- åŒ…å«å®Œæ•´çš„ä¸€ä¸ªçŸ¥è¯†ç‚¹æˆ–é¢˜ç›®ï¼Œå¹¶ä¸”åˆ—å‡ºæ‰€æœ‰çš„è§£é¢˜æ­¥éª¤
- èƒ½å¤Ÿç‹¬ç«‹ç†è§£

### 3. ç²¾ç¡®æ—¶é—´æˆ³åŒ¹é…
ä¸ºæ¯ä¸ªå†…å®¹ç‰‡æ®µæä¾›ï¼š
- **å¼€å§‹å¥**: ç‰‡æ®µçš„ç¬¬ä¸€å¥è¯ï¼ˆç”¨äºç²¾ç¡®å®šä½ï¼‰
- **ç»“æŸå¥**: ç‰‡æ®µçš„æœ€åä¸€å¥è¯ï¼ˆç”¨äºç¡®å®šè¾¹ç•Œï¼‰
- **å…³é”®å¥**: æœ€èƒ½ä»£è¡¨è¯¥ç‰‡æ®µæ ¸å¿ƒå†…å®¹çš„å¥å­

è§†é¢‘æ ‡é¢˜ï¼š{lecture_title}

è½¬å½•å†…å®¹ï¼š
{transcription_text}

è¯·ä»¥ç»“æ„åŒ–æ–‡æœ¬æ ¼å¼è¿”å›åˆ†æç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

å†…å®¹ç±»å‹: [æ¦‚å¿µè®²è§£/é¢˜ç›®å¤ä¹ /æ··åˆå†…å®¹]
å†…å®¹å­ç±»å‹: [æ–°æ¦‚å¿µå¼•å…¥/å…¬å¼æ¨å¯¼/ä¾‹é¢˜è®²è§£/ä¹ é¢˜è§£ç­”/æ€»ç»“å›é¡¾]
ç½®ä¿¡åº¦: [0.95]

ç‰‡æ®µ1:
æ ‡é¢˜: [ç‰‡æ®µæ ‡é¢˜]
æè¿°: [ç‰‡æ®µå†…å®¹æè¿°]
å¼€å§‹å¥: [ç‰‡æ®µå¼€å§‹çš„ç¬¬ä¸€å¥è¯]
ç»“æŸå¥: [ç‰‡æ®µç»“æŸçš„æœ€åä¸€å¥è¯]
å…³é”®å¥: [æœ€èƒ½ä»£è¡¨è¯¥ç‰‡æ®µæ ¸å¿ƒçš„å¥å­]
é‡è¦æ€§: [high/medium/low]
ç±»åˆ«: [æ¦‚å¿µå®šä¹‰/å…¬å¼æ¨å¯¼/ä¾‹é¢˜è®²è§£/è§£é¢˜æ­¥éª¤/æ€»ç»“å›é¡¾]
éš¾åº¦: [åŸºç¡€/ä¸­ç­‰/å›°éš¾]

ç‰‡æ®µ2:
æ ‡é¢˜: [ç‰‡æ®µæ ‡é¢˜]
æè¿°: [ç‰‡æ®µå†…å®¹æè¿°]
å¼€å§‹å¥: [ç‰‡æ®µå¼€å§‹çš„ç¬¬ä¸€å¥è¯]
ç»“æŸå¥: [ç‰‡æ®µç»“æŸçš„æœ€åä¸€å¥è¯]
å…³é”®å¥: [æœ€èƒ½ä»£è¡¨è¯¥ç‰‡æ®µæ ¸å¿ƒçš„å¥å­]
é‡è¦æ€§: [high/medium/low]
ç±»åˆ«: [æ¦‚å¿µå®šä¹‰/å…¬å¼æ¨å¯¼/ä¾‹é¢˜è®²è§£/è§£é¢˜æ­¥éª¤/æ€»ç»“å›é¡¾]
éš¾åº¦: [åŸºç¡€/ä¸­ç­‰/å›°éš¾]

æ€»ç»“: [è§†é¢‘å†…å®¹ç®€è¦æ€»ç»“]

## é‡è¦è¯´æ˜ï¼š
1. **å¼€å§‹å¥** å’Œ **ç»“æŸå¥** å¿…é¡»æ˜¯ä»è½¬å½•æ–‡æœ¬ä¸­æå–çš„å®é™…å¥å­ï¼Œå¥å­è¦å®Œæ•´ä¸”å‡†ç¡®
2. **å…³é”®å¥** åº”è¯¥æ˜¯æœ€èƒ½ä»£è¡¨è¯¥ç‰‡æ®µæ ¸å¿ƒå†…å®¹çš„å¥å­ï¼ŒåŒ…å«é‡è¦çš„å…³é”®è¯
3. ä¸è¦åŒ…å«æ—¶é—´æˆ³ï¼Œæ—¶é—´æˆ³å°†é€šè¿‡åç»­ç²¾ç¡®åŒ¹é…è·å¾—
4. æ¯ä¸ªç‰‡æ®µåº”è¯¥æœ‰æ˜ç¡®çš„è¾¹ç•Œï¼Œä¾¿äºåç»­ç²¾ç¡®å®šä½
5. å¼€å§‹å¥å’Œç»“æŸå¥åº”è¯¥åŒ…å«è¶³å¤Ÿçš„è¯æ±‡ï¼Œä¾¿äºåœ¨è½¬å½•æ–‡æœ¬ä¸­ç²¾ç¡®å®šä½
6. è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æ ¼å¼è¾“å‡ºï¼Œä¸è¦ä½¿ç”¨JSONæ ¼å¼
"""
        
        self.prompt_manager.create_prompt_template("video_analysis", default_prompt)
        print("âœ… å·²åˆ›å»ºé»˜è®¤çš„è§†é¢‘åˆ†æPrompt")

    # ğŸ†• ä¼˜åŒ–4: æ–°å¢ç¼“å­˜ç›¸å…³æ–¹æ³•
    def _get_file_hash(self, file_path: str) -> str:
        """è·å–æ–‡ä»¶hashå€¼ï¼Œç”¨äºç¼“å­˜key"""
        with open(file_path, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()[:12]  # å–å‰12ä½å³å¯
    
    def _get_cache_file_path(self, video_path: str, lecture_title: str) -> str:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        file_hash = self._get_file_hash(video_path)
        safe_title = ''.join(c for c in lecture_title if c.isalnum() or c in ('_', '-'))
        cache_filename = f"{safe_title}_{file_hash}_analysis.json"
        return os.path.join(self.cache_dir, cache_filename)
    
    def _save_analysis_cache(self, video_path: str, lecture_title: str, transcription: Dict, analysis: Dict) -> str:
        """ä¿å­˜è½¬å½•å’Œåˆ†æç»“æœåˆ°ç¼“å­˜"""
        cache_file = self._get_cache_file_path(video_path, lecture_title)
        
        cache_data = {
            "cache_info": {
                "video_path": video_path,
                "lecture_title": lecture_title,
                "file_hash": self._get_file_hash(video_path),
                "created_time": datetime.now().isoformat(),
                "cache_version": "1.0"
            },
            "transcription": transcription,
            "analysis": analysis
        }
        
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ åˆ†æç»“æœå·²ç¼“å­˜åˆ°: {cache_file}")
        return cache_file
    
    def _load_analysis_cache(self, video_path: str, lecture_title: str) -> Optional[Tuple[Dict, Dict]]:
        """ä»ç¼“å­˜åŠ è½½è½¬å½•å’Œåˆ†æç»“æœ"""
        cache_file = self._get_cache_file_path(video_path, lecture_title)
        
        if not os.path.exists(cache_file):
            return None
        
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # éªŒè¯ç¼“å­˜å®Œæ•´æ€§
            if 'transcription' not in cache_data or 'analysis' not in cache_data:
                print("âš ï¸ ç¼“å­˜æ–‡ä»¶ä¸å®Œæ•´ï¼Œå°†é‡æ–°å¤„ç†")
                return None
            
            # éªŒè¯æ–‡ä»¶hashï¼ˆå¯é€‰ï¼Œç¡®ä¿è§†é¢‘æ–‡ä»¶æ²¡æœ‰å˜åŒ–ï¼‰
            current_hash = self._get_file_hash(video_path)
            cached_hash = cache_data.get('cache_info', {}).get('file_hash', '')
            
            if current_hash != cached_hash:
                print("âš ï¸ è§†é¢‘æ–‡ä»¶å·²å˜åŒ–ï¼Œå°†é‡æ–°å¤„ç†")
                return None
            
            print(f"ğŸ“‚ ä»ç¼“å­˜åŠ è½½åˆ†æç»“æœ: {cache_file}")
            return cache_data['transcription'], cache_data['analysis']
            
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜åŠ è½½å¤±è´¥: {e}ï¼Œå°†é‡æ–°å¤„ç†")
            return None


    def extract_audio_from_video(self, video_path: str, output_audio_path: str) -> str:
        """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
        (
            ffmpeg
            .input(video_path)
            .output(output_audio_path, acodec='pcm_s16le', ac=1, ar='16k')
            .overwrite_output()
            .run(quiet=True)
        )
        return output_audio_path

    def _format_timestamp(self, seconds: float) -> str:
        """å°†ç§’æ•°è½¬æ¢ä¸ºHH:MM:SSæ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds = int(seconds % 60)
        return f"{hours:02d}:{minutes:02d}:{seconds:02d}"

    def transcribe_video_with_timestamps(self, video_path: str, model_size: str = "base") -> Dict:
        """ä½¿ç”¨Whisperè½¬å½•è§†é¢‘å¹¶è·å–æ—¶é—´æˆ³"""
        model = whisper.load_model(model_size)
        result = model.transcribe(video_path, word_timestamps=True)
        # è®°å½•è½¬å½•ä¿¡æ¯
        self._log_processing_info("transcription", {
            "text_length": len(result.get('text', '')),
            "segments_count": len(result.get('segments', [])),
            "model_size": model_size
        })
        return result

    def _find_matching_timestamps(self, start_phrase: str, end_phrase: str, key_phrase: str, transcription: Dict) -> Dict:
        """åŸºäºå…³é”®å¥å­ç²¾ç¡®åŒ¹é…æ—¶é—´æˆ³ - é«˜ç²¾åº¦ç‰ˆæœ¬"""
        try:
            segments = transcription.get('segments', [])
            if not segments:
                return {"start_time": "00:00:00", "end_time": "00:00:00", "duration_seconds": 0}
            
            print(f"ğŸ” å¼€å§‹é«˜ç²¾åº¦æ—¶é—´æˆ³åŒ¹é…:")
            print(f"  å¼€å§‹å¥: {start_phrase}")
            print(f"  ç»“æŸå¥: {end_phrase}")
            print(f"  å…³é”®å¥: {key_phrase}")
            
            start_time = None
            end_time = None
            match_method = "exact"
            
            # ğŸ†• æ”¹è¿›1: æ›´ç²¾ç¡®çš„å¥å­åŒ¹é…ç®—æ³•
            def find_exact_segment_match(target_phrase: str, segments: list, search_forward: bool = True) -> tuple:
                """æ‰¾åˆ°ç²¾ç¡®åŒ¹é…çš„ç‰‡æ®µ"""
                if not target_phrase.strip():
                    return None, "empty_phrase"
                
                target_phrase_clean = target_phrase.strip().lower()
                target_words = target_phrase_clean.split()
                
                # å¦‚æœç›®æ ‡çŸ­è¯­å¤ªçŸ­ï¼Œå¢åŠ æœ€å°é•¿åº¦è¦æ±‚
                if len(target_words) < 3:
                    return None, "phrase_too_short"
                
                best_match = None
                best_score = 0
                best_method = "no_match"
                
                # éå†ç‰‡æ®µ
                segment_list = segments if search_forward else list(reversed(segments))
                
                for segment in segment_list:
                    segment_text = segment['text'].strip().lower()
                    segment_words = segment_text.split()
                    
                    # è·³è¿‡å¤ªçŸ­çš„ç‰‡æ®µ
                    if len(segment_words) < 2:
                        continue
                    
                    # ğŸ†• æ”¹è¿›2: å¤šç§åŒ¹é…ç­–ç•¥
                    match_scores = []
                    
                    # ç­–ç•¥1: å®Œå…¨åŒ¹é…
                    if target_phrase_clean in segment_text:
                        match_scores.append(("exact", 1.0))
                    
                    # ç­–ç•¥2: è¿ç»­è¯åŒ¹é…
                    consecutive_matches = 0
                    max_consecutive = 0
                    current_consecutive = 0
                    
                    for i, word in enumerate(target_words):
                        if word in segment_words:
                            current_consecutive += 1
                            max_consecutive = max(max_consecutive, current_consecutive)
                        else:
                            current_consecutive = 0
                    
                    if max_consecutive >= 3:  # è‡³å°‘3ä¸ªè¿ç»­è¯åŒ¹é…
                        consecutive_ratio = max_consecutive / len(target_words)
                        match_scores.append(("consecutive", consecutive_ratio))
                    
                    # ç­–ç•¥3: å…³é”®è¯åŒ¹é…
                    common_words = set(target_words) & set(segment_words)
                    if len(common_words) >= 3:  # è‡³å°‘3ä¸ªè¯åŒ¹é…
                        word_match_ratio = len(common_words) / len(target_words)
                        match_scores.append(("keyword", word_match_ratio))
                    
                    # ç­–ç•¥4: æ¨¡ç³ŠåŒ¹é…ï¼ˆä½¿ç”¨ç¼–è¾‘è·ç¦»ï¼‰
                    if len(target_phrase_clean) > 10:
                        from difflib import SequenceMatcher
                        similarity = SequenceMatcher(None, target_phrase_clean, segment_text).ratio()
                        if similarity > 0.7:  # 70%ç›¸ä¼¼åº¦
                            match_scores.append(("fuzzy", similarity))
                    
                    # é€‰æ‹©æœ€ä½³åŒ¹é…ç­–ç•¥
                    if match_scores:
                        best_strategy = max(match_scores, key=lambda x: x[1])
                        strategy_name, score = best_strategy
                        
                        if score > best_score and score > 0.5:  # æé«˜åŒ¹é…é˜ˆå€¼
                            best_score = score
                            best_match = segment
                            best_method = strategy_name
                
                return best_match, best_method
            
            # ğŸ†• æ”¹è¿›3: æ™ºèƒ½æ—¶é—´èŒƒå›´ä¼°è®¡
            def estimate_reasonable_duration(segments: list, start_time: float) -> float:
                """ä¼°è®¡åˆç†çš„ç‰‡æ®µæŒç»­æ—¶é—´"""
                # è®¡ç®—æ‰€æœ‰ç‰‡æ®µçš„å¹³å‡æŒç»­æ—¶é—´
                durations = [seg['end'] - seg['start'] for seg in segments]
                avg_duration = sum(durations) / len(durations) if durations else 30
                
                # æ ¹æ®å†…å®¹ç±»å‹è°ƒæ•´æŒç»­æ—¶é—´
                if 'æ¦‚ç‡' in key_phrase or 'æ¦‚å¿µ' in key_phrase:
                    # æ¦‚å¿µè®²è§£é€šå¸¸è¾ƒçŸ­
                    return min(avg_duration * 2, 120)  # æœ€å¤š2åˆ†é’Ÿ
                elif 'ä¾‹é¢˜' in key_phrase or 'è§£é¢˜' in key_phrase:
                    # ä¾‹é¢˜è®²è§£å¯èƒ½è¾ƒé•¿
                    return min(avg_duration * 3, 180)  # æœ€å¤š3åˆ†é’Ÿ
                else:
                    # é»˜è®¤æŒç»­æ—¶é—´
                    return min(avg_duration * 2, 150)  # æœ€å¤š2.5åˆ†é’Ÿ
            
            # ğŸ†• æ”¹è¿›4: åˆ†åˆ«åŒ¹é…å¼€å§‹å’Œç»“æŸ
            start_segment, start_method = find_exact_segment_match(start_phrase, segments, True)
            end_segment, end_method = find_exact_segment_match(end_phrase, segments, False)
            
            if start_segment:
                start_time = start_segment['start']
                match_method = start_method
                print(f"âœ… åŒ¹é…å¼€å§‹å¥: {start_segment['text'][:50]}... (æ–¹æ³•: {start_method})")
            else:
                print(f"âŒ æœªæ‰¾åˆ°å¼€å§‹å¥åŒ¹é…")
            
            if end_segment:
                end_time = end_segment['end']
                print(f"âœ… åŒ¹é…ç»“æŸå¥: {end_segment['text'][:50]}... (æ–¹æ³•: {end_method})")
            else:
                print(f"âŒ æœªæ‰¾åˆ°ç»“æŸå¥åŒ¹é…")
            
            # ğŸ†• æ”¹è¿›5: æ™ºèƒ½å›é€€ç­–ç•¥
            if start_time is None:
                # å°è¯•åŸºäºå…³é”®å¥æ‰¾åˆ°å¼€å§‹æ—¶é—´
                key_segment, key_method = find_exact_segment_match(key_phrase, segments, True)
                if key_segment:
                    start_time = key_segment['start']
                    match_method = f"key_phrase_{key_method}"
                    print(f"âœ… åŸºäºå…³é”®å¥åŒ¹é…å¼€å§‹: {key_segment['text'][:50]}...")
                else:
                    # ğŸ†• æ”¹è¿›6: åŸºäºå†…å®¹ä½ç½®çš„å›é€€
                    # æ ¹æ®ç‰‡æ®µåœ¨è§†é¢‘ä¸­çš„ä½ç½®ä¼°è®¡å¼€å§‹æ—¶é—´
                    total_segments = len(segments)
                    if total_segments > 0:
                        # å‡è®¾å½“å‰ç‰‡æ®µåœ¨è§†é¢‘çš„å‰1/3ä½ç½®
                        estimated_start_index = max(0, total_segments // 3)
                        start_time = segments[estimated_start_index]['start']
                        match_method = "position_estimate"
                        print(f"âš ï¸  åŸºäºä½ç½®ä¼°è®¡å¼€å§‹æ—¶é—´: {start_time:.1f}s")
                    else:
                        start_time = segments[0]['start']
                        match_method = "default_start"
                        print(f"âš ï¸  ä½¿ç”¨é»˜è®¤å¼€å§‹æ—¶é—´: {start_time}")
            
            if end_time is None:
                # å°è¯•åŸºäºå…³é”®å¥æ‰¾åˆ°ç»“æŸæ—¶é—´
                key_segment, key_method = find_exact_segment_match(key_phrase, segments, False)
                if key_segment:
                    end_time = key_segment['end']
                    print(f"âœ… åŸºäºå…³é”®å¥åŒ¹é…ç»“æŸ: {key_segment['text'][:50]}...")
                else:
                    # ğŸ†• æ”¹è¿›7: åŸºäºåˆç†æŒç»­æ—¶é—´çš„å›é€€
                    if start_time is not None:
                        reasonable_duration = estimate_reasonable_duration(segments, start_time)
                        end_time = min(start_time + reasonable_duration, segments[-1]['end'])
                        match_method = "duration_estimate"
                        print(f"âš ï¸  åŸºäºæŒç»­æ—¶é—´ä¼°è®¡ç»“æŸæ—¶é—´: {end_time:.1f}s (æŒç»­{reasonable_duration:.1f}s)")
                    else:
                        end_time = segments[-1]['end']
                        match_method = "default_end"
                        print(f"âš ï¸  ä½¿ç”¨é»˜è®¤ç»“æŸæ—¶é—´: {end_time}")
            
            # ğŸ†• æ”¹è¿›8: æ›´ä¸¥æ ¼çš„æ—¶é—´èŒƒå›´éªŒè¯å’Œä¿®æ­£
            if start_time is not None and end_time is not None:
                duration = end_time - start_time
                
                # æ£€æŸ¥æ—¶é—´èŒƒå›´æ˜¯å¦åˆç†
                if duration < 5:  # å¤ªçŸ­
                    reasonable_duration = estimate_reasonable_duration(segments, start_time)
                    end_time = min(start_time + reasonable_duration, segments[-1]['end'])
                    print(f"âš ï¸  æ—¶é—´èŒƒå›´å¤ªçŸ­ï¼Œè°ƒæ•´ä¸º{reasonable_duration:.1f}ç§’")
                elif duration > 300:  # å¤ªé•¿ï¼ˆ5åˆ†é’Ÿï¼‰
                    # å°è¯•æ‰¾åˆ°æ›´åˆç†çš„ç»“æŸæ—¶é—´
                    reasonable_duration = estimate_reasonable_duration(segments, start_time)
                    end_time = min(start_time + reasonable_duration, segments[-1]['end'])
                    print(f"âš ï¸  æ—¶é—´èŒƒå›´å¤ªé•¿ï¼Œè°ƒæ•´ä¸º{reasonable_duration:.1f}ç§’")
                
                # ç¡®ä¿ç»“æŸæ—¶é—´ä¸æ—©äºå¼€å§‹æ—¶é—´
                if end_time <= start_time:
                    reasonable_duration = estimate_reasonable_duration(segments, start_time)
                    end_time = min(start_time + reasonable_duration, segments[-1]['end'])
                    print(f"âš ï¸  ç»“æŸæ—¶é—´æ—©äºå¼€å§‹æ—¶é—´ï¼Œè°ƒæ•´ä¸º{reasonable_duration:.1f}ç§’å")
                
                duration = end_time - start_time
            else:
                duration = 0
            
            timestamp_info = {
                "start_time": self._format_timestamp(start_time) if start_time else "00:00:00",
                "end_time": self._format_timestamp(end_time) if end_time else "00:00:00",
                "duration_seconds": duration,
                "start_seconds": start_time if start_time else 0,
                "end_seconds": end_time if end_time else 0,
                "match_method": match_method
            }
            
            print(f"ğŸ¯ æ—¶é—´æˆ³åŒ¹é…ç»“æœ:")
            print(f"  å¼€å§‹æ—¶é—´: {timestamp_info['start_time']} ({start_time:.1f}s)")
            print(f"  ç»“æŸæ—¶é—´: {timestamp_info['end_time']} ({end_time:.1f}s)")
            print(f"  æŒç»­æ—¶é—´: {duration:.1f}ç§’")
            print(f"  åŒ¹é…æ–¹æ³•: {match_method}")
            
            self._log_processing_info("timestamp_matching", {
                "start_phrase": start_phrase,
                "end_phrase": end_phrase,
                "key_phrase": key_phrase,
                "timestamp_info": timestamp_info,
                "match_method": match_method
            })
            
            return timestamp_info
            
        except Exception as e:
            print(f"âŒ æ—¶é—´æˆ³åŒ¹é…å¤±è´¥: {e}")
            return {"start_time": "00:00:00", "end_time": "00:00:00", "duration_seconds": 0}
    
    def analyze_video_content(self, transcription: Dict, lecture_title: str) -> Dict:
        """åˆ†æè§†é¢‘å†…å®¹ï¼Œæ™ºèƒ½è¯†åˆ«å†…å®¹ç±»å‹å’ŒçŸ¥è¯†ç‚¹åˆ‡ç‰‡ - ä½¿ç”¨PromptManagerç‰ˆæœ¬"""
        
        # ğŸ†• ä½¿ç”¨PromptManagerè·å–Prompt
        try:
            prompt = self.prompt_manager.get_prompt(
                "video_analysis",
                lecture_title=lecture_title,
                transcription_text=transcription['text']
            )
        except Exception as e:
            print(f"âŒ è·å–è§†é¢‘åˆ†æPromptå¤±è´¥: {e}")
            # é™çº§åˆ°ç¡¬ç¼–ç Promptï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
            prompt = self._get_fallback_analysis_prompt(transcription, lecture_title)
        
        # è°ƒç”¨LLMåˆ†æ
        response = self.model.generate_content(prompt)
        estimated_tokens = len(prompt.split()) + len(transcription['text'].split())
        
        # æ£€æŸ¥APIå“åº”
        # æ£€æŸ¥å“åº”çŠ¶æ€å’Œå†…å®¹
        if not response:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: å“åº”ä¸ºç©º")
            return {
                "content_type": "æœªçŸ¥",
                "content_subtype": "æœªçŸ¥",
                "confidence": 0.0,
                "content_segments": [],
                "summary": "APIè°ƒç”¨å¤±è´¥"
            }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰finish_reasoné”™è¯¯
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'finish_reason'):
                finish_reason = candidate.finish_reason
                if finish_reason in [0, 1]:  # 0å’Œ1éƒ½è¡¨ç¤ºæ­£å¸¸å®Œæˆ
                    print(f"âœ… APIè°ƒç”¨æ­£å¸¸å®Œæˆ (finish_reason={finish_reason})")
                elif finish_reason == 2:
                    print(f"âš ï¸ APIè°ƒç”¨è¾¾åˆ°æœ€å¤§tokené™åˆ¶ (finish_reason=2)")
                elif finish_reason == 3:
                    print(f"âŒ APIè°ƒç”¨è¢«å®‰å…¨è¿‡æ»¤é˜»æ­¢ (finish_reason=3)")
                    return {
                        "content_type": "æœªçŸ¥",
                        "content_subtype": "æœªçŸ¥",
                        "confidence": 0.0,
                        "content_segments": [],
                        "summary": "APIè°ƒç”¨è¢«å®‰å…¨è¿‡æ»¤é˜»æ­¢"
                    }
                elif finish_reason == 4:
                    print(f"âš ï¸ APIè°ƒç”¨è¾¾åˆ°é€’å½’é™åˆ¶ (finish_reason=4)")
                else:
                    print(f"âš ï¸ APIè°ƒç”¨å‡ºç°æœªçŸ¥çŠ¶æ€ (finish_reason={finish_reason})")
        
        # æ£€æŸ¥å“åº”æ–‡æœ¬
        if not hasattr(response, 'text') or not response.text:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: å“åº”æ²¡æœ‰æ–‡æœ¬å†…å®¹")
            return {
                "content_type": "æœªçŸ¥",
                "content_subtype": "æœªçŸ¥",
                "confidence": 0.0,
                "content_segments": [],
                "summary": "APIå“åº”æ²¡æœ‰æ–‡æœ¬å†…å®¹"
            }
        
        print(f"âœ… APIè°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(response.text)}")
        
        # æ¸…ç†å“åº”ï¼ˆç§»é™¤å¯èƒ½çš„markdownåŒ…è£…ï¼‰
        cleaned_response = response.text
        if cleaned_response.startswith('```'):
            cleaned_response = cleaned_response.replace('```', '').strip()
        
        try:
            # è§£æç»“æ„åŒ–æ–‡æœ¬å“åº”
            result = self._parse_structured_response(cleaned_response)
            self._log_processing_info("content_analysis", {
                "token_count": estimated_tokens,
                "content_type": result.get("content_type", ""),
                "content_subtype": result.get("content_subtype", ""),
                "confidence": result.get("confidence", 0.0),
                "segments_count": len(result.get("content_segments", [])),
                "api_response_length": len(response.text),
                "prompt_used": "video_analysis (from file)"  # ğŸ†• è®°å½•ä½¿ç”¨çš„Promptæ¥æº
            })
            return result
        except Exception as e:
            print(f"ç»“æ„åŒ–æ–‡æœ¬è§£æå¤±è´¥: {e}")
            print(f"APIå“åº”å†…å®¹: {response.text[:500]}...")
            print(f"æ¸…ç†åå†…å®¹: {cleaned_response[:500]}...")
            return {
                "content_type": "æœªçŸ¥",
                "content_subtype": "æœªçŸ¥",
                "confidence": 0.0,
                "content_segments": [],
                "summary": "åˆ†æå¤±è´¥"
            }
    
    def _get_fallback_analysis_prompt(self, transcription: Dict, lecture_title: str) -> str:
        """è·å–å¤‡ç”¨çš„ç¡¬ç¼–ç åˆ†æPromptï¼ˆå½“æ–‡ä»¶Promptä¸å¯ç”¨æ—¶ï¼‰"""
        return f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯¾ç¨‹å†…å®¹åˆ†æåŠ©æ‰‹ã€‚è¯·åˆ†æä»¥ä¸‹è§†é¢‘è½¬å½•å†…å®¹ï¼š

è§†é¢‘æ ‡é¢˜ï¼š{lecture_title}
è½¬å½•å†…å®¹ï¼š{transcription['text']}

è¯·è¿”å›ç»“æ„åŒ–åˆ†æç»“æœ...
"""
    
    def _parse_structured_response(self, text: str) -> Dict:
        """è§£æç»“æ„åŒ–æ–‡æœ¬å“åº”"""
        result = {
            "content_type": "æœªçŸ¥",
            "content_subtype": "æœªçŸ¥", 
            "confidence": 0.0,
            "content_segments": [],
            "summary": ""
        }
        
        lines = text.strip().split('\n')
        current_segment = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # è§£æå†…å®¹ç±»å‹
            if line.startswith('å†…å®¹ç±»å‹:') or line.startswith('Content Type:'):
                result["content_type"] = line.split(':', 1)[1].strip()
            elif line.startswith('å†…å®¹å­ç±»å‹:') or line.startswith('Content Subtype:'):
                result["content_subtype"] = line.split(':', 1)[1].strip()
            elif line.startswith('ç½®ä¿¡åº¦:') or line.startswith('Confidence:'):
                try:
                    confidence_str = line.split(':', 1)[1].strip()
                    result["confidence"] = float(confidence_str)
                except:
                    result["confidence"] = 0.0
            elif line.startswith('æ€»ç»“:') or line.startswith('Summary:'):
                result["summary"] = line.split(':', 1)[1].strip()
            elif (line.startswith('ç‰‡æ®µ') or line.startswith('Segment')) and ':' in line:
                # å¼€å§‹æ–°ç‰‡æ®µ
                if current_segment:
                    result["content_segments"].append(current_segment)
                current_segment = {
                    "id": f"seg_{len(result['content_segments'])+1:03d}",
                    "title": "",
                    "description": "",
                    "start_phrase": "",
                    "end_phrase": "",
                    "key_phrase": "",
                    "importance": "",
                    "category": "",
                    "difficulty": ""
                }
            elif current_segment and ':' in line:
                # è§£æç‰‡æ®µå±æ€§
                key, value = line.split(':', 1)
                key = key.strip()
                value = value.strip()
                
                if key in ['æ ‡é¢˜', 'Title']:
                    current_segment["title"] = value
                elif key in ['æè¿°', 'Description']:
                    current_segment["description"] = value
                elif key in ['å¼€å§‹å¥', 'Start Sentence']:
                    current_segment["start_phrase"] = value
                elif key in ['ç»“æŸå¥', 'End Sentence']:
                    current_segment["end_phrase"] = value
                elif key in ['å…³é”®å¥', 'Key Sentence']:
                    current_segment["key_phrase"] = value
                elif key in ['é‡è¦æ€§', 'Importance']:
                    current_segment["importance"] = value
                elif key in ['ç±»åˆ«', 'Category']:
                    current_segment["category"] = value
                elif key in ['éš¾åº¦', 'Difficulty']:
                    current_segment["difficulty"] = value
        
        # æ·»åŠ æœ€åä¸€ä¸ªç‰‡æ®µ
        if current_segment:
            result["content_segments"].append(current_segment)
            
        return result

    # ğŸ†• ä¼˜åŒ–5: é‡å†™process_videoæ–¹æ³•ï¼Œæ·»åŠ ç¼“å­˜åŠŸèƒ½
    def process_video(self, video_path: str, lecture_title: str, language: str = "ä¸­æ–‡") -> Dict:
        """å¤„ç†è§†é¢‘çš„å®Œæ•´æµç¨‹ - ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆæ”¯æŒç¼“å­˜ï¼‰"""
        from datetime import datetime
        start_time = datetime.now()
        
        print("ğŸš€ å¼€å§‹è§†é¢‘å¤„ç†æµç¨‹...")
        print(f"è§†é¢‘: {video_path}")
        print(f"æ ‡é¢˜: {lecture_title}")
        
        # ğŸ†• ä¼˜åŒ–6: å°è¯•ä»ç¼“å­˜åŠ è½½è½¬å½•å’Œåˆ†æç»“æœ
        cached_result = self._load_analysis_cache(video_path, lecture_title)
        
        if cached_result:
            transcription, analysis = cached_result
            print("âœ… ä½¿ç”¨ç¼“å­˜çš„è½¬å½•å’Œåˆ†æç»“æœ")
            
            # ğŸ†• ä¿®å¤ï¼šä»ç¼“å­˜åŠ è½½æ—¶ä¹Ÿè¦æ›´æ–°å¤„ç†æ—¥å¿—
            if 'content_segments' in analysis:
                self.processing_log['segments_count'] = len(analysis['content_segments'])
                self.processing_log['content_type'] = analysis.get('content_type', '')
                self.processing_log['content_subtype'] = analysis.get('content_subtype', '')
                self.processing_log['confidence'] = analysis.get('confidence', 0.0)
                self.processing_log['transcription_length'] = len(transcription.get('text', ''))
                
                # è®¡ç®—ä¼°è®¡çš„tokenæ•°é‡
                estimated_tokens = len(transcription.get('text', '').split()) * 2  # ç²—ç•¥ä¼°è®¡
                self.processing_log['token_count'] = estimated_tokens
                self.processing_log['api_calls'] = 1  # å‡è®¾ä¹‹å‰è°ƒç”¨è¿‡API
                
                print(f"ğŸ“Š ä»ç¼“å­˜æ¢å¤å¤„ç†ç»Ÿè®¡:")
                print(f"  - å†…å®¹ç‰‡æ®µæ•°: {self.processing_log['segments_count']}")
                print(f"  - å†…å®¹ç±»å‹: {self.processing_log['content_type']}")
                print(f"  - è½¬å½•é•¿åº¦: {self.processing_log['transcription_length']}å­—ç¬¦")
        else:
            # ç¬¬ä¸€æ¬¡å¤„ç†ï¼šè½¬å½•å’Œåˆ†æ
            print("ğŸ¬ æ­£åœ¨è½¬å½•è§†é¢‘...")
            transcription = self.transcribe_video_with_timestamps(video_path)
            
            print("ğŸ§  æ­£åœ¨åˆ†æè§†é¢‘å†…å®¹...")
            analysis = self.analyze_video_content(transcription, lecture_title)
            
            print("â° æ­£åœ¨ç²¾ç¡®åŒ¹é…æ—¶é—´æˆ³...")
            if 'content_segments' in analysis:
                for i, segment in enumerate(analysis['content_segments']):
                    timestamp_info = self._find_matching_timestamps(
                        segment.get('start_phrase', ''),
                        segment.get('end_phrase', ''),
                        segment.get('key_phrase', ''),
                        transcription
                    )
                    segment.update(timestamp_info)
                    self._log_processing_info("segment_details", {
                        "segment_id": segment.get('id', f'seg_{i+1:03d}'),
                        "title": segment.get('title', ''),
                        "start_phrase": segment.get('start_phrase', ''),
                        "end_phrase": segment.get('end_phrase', ''),
                        "key_phrase": segment.get('key_phrase', ''),
                        "importance": segment.get('importance', ''),
                        "category": segment.get('category', ''),
                        "difficulty": segment.get('difficulty', ''),
                        "timestamp_info": timestamp_info
                    })
                    print(f"âœ… ç‰‡æ®µ '{segment.get('title', '')}' åŒ¹é…åˆ°æ—¶é—´æˆ³: {timestamp_info['start_time']} - {timestamp_info['end_time']} (æ—¶é•¿: {timestamp_info['duration_seconds']:.1f}ç§’)")
            
            # ğŸ†• ä¼˜åŒ–7: ä¿å­˜è½¬å½•å’Œåˆ†æç»“æœåˆ°ç¼“å­˜
            self._save_analysis_cache(video_path, lecture_title, transcription, analysis)
        
        # ğŸ†• ä¼˜åŒ–8: æ¯æ¬¡éƒ½é‡æ–°ç”ŸæˆSummaryï¼ˆå› ä¸ºå¯èƒ½è°ƒæ•´promptï¼‰
        print("ğŸ”„ æ­£åœ¨æ•´åˆå®Œæ•´Summary...")
        summary_result = self.summary_integrator.generate_summary(
            analysis, transcription, lecture_title, language
        )

        # ä¿ç•™åŸæœ‰åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰
        print("ğŸ“ æ­£åœ¨ç”Ÿæˆåˆ†æ®µç¬”è®°...")
        notes = "åˆ†æ®µç¬”è®°åŠŸèƒ½æš‚æœªå®ç°"  # ä¸´æ—¶å ä½ç¬¦
        
        print("ğŸ“‹ æ­£åœ¨åˆ›å»ºåˆ†æ®µæ‘˜è¦...")
        summary = "åˆ†æ®µæ‘˜è¦åŠŸèƒ½æš‚æœªå®ç°"  # ä¸´æ—¶å ä½ç¬¦
        summary_with_timestamps = "å¸¦æ—¶é—´æˆ³çš„åˆ†æ®µæ‘˜è¦åŠŸèƒ½æš‚æœªå®ç°"  # ä¸´æ—¶å ä½ç¬¦
        
        end_time = datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        self.processing_log["processing_time"] = processing_time
        self._print_processing_report()
        
        # ğŸ†• ä¼˜åŒ–9: è¿”å›æ•´åˆåçš„ç»“æœ
        return {
            "transcription": transcription,
            "analysis": analysis,
            "notes": notes,  # åŸæœ‰åˆ†æ®µç¬”è®°
            "summary": summary,  # åŸæœ‰åˆ†æ®µæ‘˜è¦
            "summary_with_timestamps": summary_with_timestamps,
            
            # ğŸ†• æ–°å¢æ•´åˆSummaryç›¸å…³å­—æ®µ
            "integrated_summary": summary_result["summary"],
            "timestamp_mapping": summary_result["timestamp_mapping"],
            "knowledge_points": summary_result["knowledge_points"],
            "summary_statistics": self.summary_integrator.get_summary_statistics(
                summary_result["summary"], 
                summary_result["knowledge_points"]
            ),
            
            "lecture_title": lecture_title,
            "language": language,
            "processing_log": self.processing_log,
            "cache_used": cached_result is not None  # ğŸ†• æ ‡è¯†æ˜¯å¦ä½¿ç”¨äº†ç¼“å­˜
        }

    def _print_processing_report(self):
        print("\n" + "="*60)
        print("ğŸ“Š è§†é¢‘å¤„ç†è¯¦ç»†æŠ¥å‘Š")
        print("="*60)
        print(f"ğŸ§® Tokenæ•°é‡: {self.processing_log['token_count']:,}")
        print(f"ğŸ“Š å†…å®¹ç‰‡æ®µæ•°: {self.processing_log['segments_count']}")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {self.processing_log['processing_time']:.2f}ç§’")
        print(f"ğŸ“ è½¬å½•æ–‡æœ¬é•¿åº¦: {self.processing_log['transcription_length']}å­—ç¬¦")
        print(f"ğŸ” APIè°ƒç”¨æ¬¡æ•°: {self.processing_log['api_calls']}")
        print(f"ğŸ“‹ å†…å®¹ç±»å‹: {self.processing_log['content_type']}")
        print(f"ğŸ—‚ï¸  å†…å®¹å­ç±»å‹: {self.processing_log['content_subtype']}")
        print(f"ğŸ¯ ç½®ä¿¡åº¦: {self.processing_log['confidence']:.2f}")
        print("\nğŸ“‹ å†…å®¹ç‰‡æ®µè¯¦æƒ…:")
        for i, segment in enumerate(self.processing_log['segments_details']):
            print(f"  {i+1}. {segment['title']}")
            print(f"     å¼€å§‹å¥: {segment['start_phrase'][:50]}...")
            print(f"     ç»“æŸå¥: {segment['end_phrase'][:50]}...")
            print(f"     å…³é”®å¥: {segment['key_phrase'][:50]}...")
            print(f"     æ—¶é—´æˆ³: {segment['timestamp_info']['start_time']} - {segment['timestamp_info']['end_time']}")
            print(f"     æ—¶é•¿: {segment['timestamp_info']['duration_seconds']:.1f}ç§’")
            print(f"     é‡è¦æ€§: {segment['importance']}, ç±»åˆ«: {segment['category']}, éš¾åº¦: {segment['difficulty']}")
            print()
        print("="*60)

    def _log_processing_info(self, stage: str, info: Dict):
        """è®°å½•å¤„ç†ä¿¡æ¯"""
        print(f"ğŸ” [{stage}] {info}")
        if stage == "transcription":
            self.processing_log["transcription_length"] = info.get("text_length", 0)
            self.processing_log["segments_count"] = info.get("segments_count", 0)
        elif stage == "content_analysis":
            self.processing_log["token_count"] = info.get("token_count", 0)
            self.processing_log["api_calls"] += 1
            self.processing_log["content_type"] = info.get("content_type", "")
            self.processing_log["content_subtype"] = info.get("content_subtype", "")
            self.processing_log["confidence"] = info.get("confidence", 0.0)
        elif stage == "timestamp_matching":
            self.processing_log["timestamp_matches"].append(info)
        elif stage == "segment_details":
            self.processing_log["segments_details"].append(info)
    
    # ğŸ†• ä¼˜åŒ–10: æ–°å¢ç¼“å­˜ç®¡ç†æ–¹æ³•
    def clear_cache(self, lecture_title: str = None):
        """æ¸…ç†ç¼“å­˜æ–‡ä»¶"""
        if lecture_title:
            # æ¸…ç†ç‰¹å®šè¯¾ç¨‹çš„ç¼“å­˜
            pattern = f"*{lecture_title}*_analysis.json"
            import glob
            cache_files = glob.glob(os.path.join(self.cache_dir, pattern))
            for cache_file in cache_files:
                os.remove(cache_file)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤ç¼“å­˜: {cache_file}")
        else:
            # æ¸…ç†æ‰€æœ‰ç¼“å­˜
            import glob
            cache_files = glob.glob(os.path.join(self.cache_dir, "*_analysis.json"))
            for cache_file in cache_files:
                os.remove(cache_file)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤ç¼“å­˜: {cache_file}")
    
    def list_cache_files(self):
        """åˆ—å‡ºæ‰€æœ‰ç¼“å­˜æ–‡ä»¶"""
        import glob
        cache_files = glob.glob(os.path.join(self.cache_dir, "*_analysis.json"))
        print("ğŸ“‚ ç¼“å­˜æ–‡ä»¶åˆ—è¡¨:")
        for cache_file in cache_files:
            file_size = os.path.getsize(cache_file) / 1024  # KB
            mtime = datetime.fromtimestamp(os.path.getmtime(cache_file))
            print(f"  - {os.path.basename(cache_file)} ({file_size:.1f}KB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})")
    
    # ğŸ†• æ–°å¢Promptç®¡ç†ç›¸å…³æ–¹æ³•
    def update_analysis_prompt(self, new_prompt_content: str):
        """
        æ›´æ–°è§†é¢‘åˆ†æPrompt
        
        Args:
            new_prompt_content: æ–°çš„Promptå†…å®¹
        """
        self.prompt_manager.create_prompt_template("video_analysis", new_prompt_content)
        print("âœ… å·²æ›´æ–°è§†é¢‘åˆ†æPrompt")
    
    def reload_prompts(self):
        """é‡æ–°åŠ è½½æ‰€æœ‰Promptæ¨¡æ¿"""
        self.prompt_manager.clear_cache()
        print("ğŸ”„ å·²é‡æ–°åŠ è½½æ‰€æœ‰Promptæ¨¡æ¿")
    
    def list_available_prompts(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„Prompt"""
        prompts = self.prompt_manager.list_available_prompts()
        print("ğŸ“‹ å¯ç”¨çš„Promptæ¨¡æ¿:")
        for prompt in prompts:
            info = self.prompt_manager.get_prompt_info(prompt)
            if info.get('exists'):
                print(f"  - {prompt}.md ({info.get('word_count', 0)} è¯)")
            else:
                print(f"  - {prompt}.md (æ–‡ä»¶ä¸å­˜åœ¨)")
    
    def get_prompt_statistics(self):
        """è·å–Promptä½¿ç”¨ç»Ÿè®¡"""
        return {
            "available_prompts": self.prompt_manager.list_available_prompts(),
            "video_analysis_info": self.prompt_manager.get_prompt_info("video_analysis"),
            "prompts_directory": self.prompt_manager.prompts_dir
        }