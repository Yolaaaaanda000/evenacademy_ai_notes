"""
é¢˜ç›®åŒ¹é…å™¨ - æ ¹æ®çŸ¥è¯†ç‚¹æ ‡ç­¾åŒ¹é…ç›¸å…³é¢˜ç›®
"""

import pandas as pd
import os
import re
from typing import List, Dict, Optional

# ---------------- VVVV NEW CSVMatcher Class VVVV ----------------

class CSVMatcher:
    """
    CSVé¢˜åº“åŒ¹é…å™¨ - [V2 - æ•°æ®é©±åŠ¨ç‰ˆæœ¬]
    åœ¨åˆå§‹åŒ–æ—¶ä» mapping.csv åŠ¨æ€åŠ è½½çŸ¥è¯†ç‚¹å’Œå…³é”®è¯ã€‚
    """
    
    def __init__(self, mapping_filepath='data/knowledge/mapping.csv'):
        self.questions_cache = None
        # ğŸ†• æ–°å¢ï¼šæ‰©å±•çš„å…³é”®è¯æ˜ å°„
        self.extended_keyword_mapping = self._create_extended_keyword_mapping()
        # åŠ è½½çŸ¥è¯†ç‚¹å…³é”®è¯æ˜ å°„
        self.topic_keywords = self._load_topic_keywords_from_csv(mapping_filepath)

    def _create_extended_keyword_mapping(self) -> Dict[str, List[str]]:
        """
        ğŸ†• åˆ›å»ºæ‰©å±•çš„å…³é”®è¯æ˜ å°„ï¼ŒåŒ…å«æ›´å¤šä¸­è‹±æ–‡å…³é”®è¯
        """
        return {
            # æ¦‚ç‡ç›¸å…³
            'prob': ['probability', 'prob', 'chance', 'random', 'likely', 'unlikely', 'odds', 'æ¦‚ç‡', 'éšæœº', 'å¯èƒ½æ€§', 'æœŸæœ›', 'æœŸæœ›å€¼'],
            'Expectation': ['expectation', 'expected value', 'mean', 'æœŸæœ›', 'æœŸæœ›å€¼', 'å¹³å‡å€¼', 'æ•°å­¦æœŸæœ›'],
            
            # å‡ ä½•ç›¸å…³
            'geom': ['geometry', 'geometric', 'triangle', 'circle', 'area', 'perimeter', 'volume', 'å‡ ä½•', 'å›¾å½¢', 'é¢ç§¯', 'å‘¨é•¿', 'ä½“ç§¯', 'ä¸‰è§’å½¢', 'åœ†å½¢', 'æ­£æ–¹å½¢', 'çŸ©å½¢'],
            'area': ['area', 'surface', 'square', 'rectangle', 'é¢ç§¯', 'è¡¨é¢ç§¯', 'å¹³æ–¹', 'çŸ©å½¢'],
            'circle': ['circle', 'circumference', 'radius', 'diameter', 'arc', 'åœ†', 'åœ†å‘¨', 'åŠå¾„', 'ç›´å¾„', 'å¼§'],
            'angle': ['angle', 'degree', 'radian', 'trigonometry', 'è§’', 'è§’åº¦', 'å¼§åº¦', 'ä¸‰è§’å‡½æ•°'],
            'sim': ['similar', 'similarity', 'proportion', 'ratio', 'ç›¸ä¼¼', 'æ¯”ä¾‹', 'ç›¸ä¼¼æ€§'],
            'length': ['length', 'distance', 'perimeter', 'é•¿åº¦', 'è·ç¦»', 'å‘¨é•¿'],
            '3d': ['3d', 'three dimensional', 'volume', 'solid', 'ä¸‰ç»´', 'ä½“ç§¯', 'ç«‹ä½“'],
            'coor': ['coordinate', 'coordinate geometry', 'graph', 'åæ ‡', 'åæ ‡ç³»', 'å›¾å½¢'],
            
            # ä»£æ•°ç›¸å…³
            'misa': ['miscellaneous algebra', 'algebra', 'algebraic', 'ä»£æ•°', 'ä»£æ•°è¿ç®—'],
            'complex': ['complex', 'imaginary', 'real', 'plane', 'å¤æ•°', 'è™šæ•°', 'å®æ•°', 'å¤å¹³é¢'],
            'function': ['function', 'functional', 'equation', 'å‡½æ•°', 'æ–¹ç¨‹', 'f(x)', 'y='],
            'equation': ['equation', 'inequality', 'solve', 'solution', 'æ–¹ç¨‹', 'ä¸ç­‰å¼', 'è§£', 'æ±‚è§£'],
            'poly': ['polynomial', 'degree', 'coefficient', 'å¤šé¡¹å¼', 'æ¬¡æ•°', 'ç³»æ•°'],
            'seq': ['sequence', 'series', 'arithmetic', 'geometric', 'æ•°åˆ—', 'çº§æ•°', 'ç­‰å·®æ•°åˆ—', 'ç­‰æ¯”æ•°åˆ—'],
            'log': ['logarithm', 'log', 'exponential', 'å¯¹æ•°', 'æŒ‡æ•°', 'å¯¹æ•°å‡½æ•°'],
            'exp': ['exponent', 'exponential', 'power', 'æŒ‡æ•°', 'å¹‚', 'æŒ‡æ•°å‡½æ•°'],
            'trig': ['trigonometry', 'sine', 'cosine', 'tangent', 'ä¸‰è§’', 'ä¸‰è§’å‡½æ•°', 'æ­£å¼¦', 'ä½™å¼¦', 'æ­£åˆ‡'],
            'stats': ['statistics', 'stat', 'data', 'distribution', 'ç»Ÿè®¡', 'æ•°æ®', 'åˆ†å¸ƒ', 'å‡å€¼', 'ä¸­ä½æ•°'],
            
            # æ•°è®ºç›¸å…³
            'div': ['divisibility', 'divisible', 'factor', 'multiple', 'æ•´é™¤', 'æ•´é™¤æ€§', 'å€æ•°', 'å› æ•°'],
            'mod': ['modular', 'modulo', 'remainder', 'congruent', 'æ¨¡', 'æ¨¡è¿ç®—', 'åŒä½™', 'ä½™æ•°'],
            'factor': ['factor', 'divisor', 'prime', 'composite', 'å› æ•°', 'å› å­', 'è´¨æ•°', 'åˆæ•°'],
            'base': ['base', 'representation', 'number system', 'è¿›åˆ¶', 'è¡¨ç¤º', 'æ•°åˆ¶'],
            'lcm': ['lcm', 'least common multiple', 'multiple', 'æœ€å°å…¬å€æ•°', 'å…¬å€æ•°'],
            'digit': ['digit', 'number', 'representation', 'æ•°å­—', 'æ•°ä½', 'è¡¨ç¤º'],
            
            # è®¡æ•°ç›¸å…³
            'count': ['counting', 'combinatorics', 'permutation', 'combination', 'è®¡æ•°', 'æ’åˆ—', 'ç»„åˆ', 'ç»„åˆæ•°å­¦'],
            'set': ['set', 'set theory', 'element', 'subset', 'union', 'intersection', 'complement', 'é›†åˆ', 'é›†åˆè®º', 'å…ƒç´ ', 'å­é›†', 'å¹¶é›†', 'äº¤é›†', 'è¡¥é›†'],
            'Markov': ['markov', 'chain', 'probability', 'state', 'é©¬å°”å¯å¤«', 'é“¾', 'çŠ¶æ€'],
            'Recursion': ['recursion', 'recursive', 'recurrence', 'é€’å½’', 'é€’æ¨', 'é€’æ¨å…³ç³»'],
            'logic': ['logic', 'logical', 'boolean', 'é€»è¾‘', 'å¸ƒå°”', 'é€»è¾‘è¿ç®—'],
            'uniform': ['uniform', 'distribution', 'probability', 'å‡åŒ€', 'åˆ†å¸ƒ', 'å‡åŒ€åˆ†å¸ƒ'],
            'game': ['game', 'strategy', 'winning', 'æ¸¸æˆ', 'ç­–ç•¥', 'è·èƒœ'],
        }

    def _load_topic_keywords_from_csv(self, filepath: str) -> Dict[str, List[str]]:
        """
        NEW: ä»mapping.csvæ–‡ä»¶åŠ è½½å¹¶è§£æä¸»é¢˜å…³é”®è¯ã€‚
        è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œé”®æ˜¯Topicä»£ç (å¦‚'prob', 'geom'),å€¼æ˜¯å…³é”®è¯åˆ—è¡¨ã€‚
        """
        try:
            mapping_df = pd.read_csv(filepath)
            topic_dict = {}
            for _, row in mapping_df.iterrows():
                # ä½¿ç”¨ 'topic_code' åˆ—ä½œä¸ºé”®, ä¾‹å¦‚ 'prob', 'geom'
                topic_code = row['topic_code']
                # ä½¿ç”¨ 'Topic' åˆ—ä½œä¸ºå…³é”®è¯æè¿°
                topic_description = row.get('Topic', '')
                if pd.notna(topic_code) and pd.notna(topic_description):
                    # å°†ä¸»é¢˜æè¿°ä½œä¸ºå…³é”®è¯ï¼Œå¹¶æ·»åŠ æ‰©å±•çš„å…³é”®è¯
                    keywords = [topic_description.lower()]
                    
                    # æ·»åŠ æ‰©å±•çš„å…³é”®è¯æ˜ å°„
                    if topic_code in self.extended_keyword_mapping:
                        keywords.extend(self.extended_keyword_mapping[topic_code])
                    
                    topic_dict[topic_code] = keywords
            print(f"âœ… æˆåŠŸä» {filepath} åŠ è½½ {len(topic_dict)} ä¸ªçŸ¥è¯†ç‚¹å…³é”®è¯ã€‚")
            return topic_dict
        except FileNotFoundError:
            print(f"âŒ é”™è¯¯: æ˜ å°„æ–‡ä»¶ {filepath} æœªæ‰¾åˆ°ã€‚")
            return {}
        except Exception as e:
            print(f"âŒ è§£ææ˜ å°„æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return {}

    def match_by_knowledge_point_keywords(self, knowledge_point: str, questions_data: List[Dict]) -> List[Dict]:
        """
        ğŸ†• æ–°å¢ï¼šåŸºäºçŸ¥è¯†ç‚¹å…³é”®è¯çš„ç›´æ¥åŒ¹é…æ–¹æ³•
        ä»çŸ¥è¯†ç‚¹æ–‡æœ¬ä¸­æå–å…³é”®è¯ï¼Œç›´æ¥ä¸é¢˜ç›®çš„topicè¿›è¡ŒåŒ¹é…
        """
        # 1. ä»çŸ¥è¯†ç‚¹æ–‡æœ¬ä¸­æå–å…³é”®è¯
        extracted_keywords = self._extract_keywords_from_knowledge_point(knowledge_point)
        
        if not extracted_keywords:
            print(f"âš ï¸ å¯¹äºçŸ¥è¯†ç‚¹ '{knowledge_point[:30]}...'ï¼Œæœªèƒ½æå–å‡ºä»»ä½•å…³é”®è¯ã€‚")
            return []

        print(f"ğŸ” ä»çŸ¥è¯†ç‚¹æå–çš„å…³é”®è¯: {extracted_keywords}")

        # 2. åŒ¹é…é¢˜ç›®
        matches = []
        for question in questions_data:
            question_topic = str(question.get('Topic', '')).lower()
            question_division = str(question.get('Division', '')).lower()
            question_text = str(question.get('é¢˜ç›®', ''))
            
            # è®¡ç®—åŒ¹é…åˆ†æ•°
            match_score = self._calculate_keyword_match_score(extracted_keywords, question_topic, question_division, question_text)
            
            if match_score > 0:
                question_with_score = question.copy()
                question_with_score['match_score'] = match_score
                question_with_score['extracted_keywords'] = extracted_keywords
                question_with_score['matched_keywords'] = self._get_matched_keywords(extracted_keywords, question_topic, question_division, question_text)
                matches.append(question_with_score)
        
        # æŒ‰åŒ¹é…åˆ†æ•°æ’åº
        matches.sort(key=lambda x: x['match_score'], reverse=True)
        return matches

    def _extract_keywords_from_knowledge_point(self, knowledge_point: str) -> List[str]:
        """
        ğŸ†• ä»çŸ¥è¯†ç‚¹æ–‡æœ¬ä¸­æå–å…³é”®è¯
        """
        kp_lower = knowledge_point.lower()
        extracted_keywords = []
        
        # 1. ç›´æ¥åŒ¹é…topic_code
        for topic_code, keywords in self.topic_keywords.items():
            for keyword in keywords:
                if keyword.lower() in kp_lower:
                    extracted_keywords.append(topic_code)
                    break
        
        # 2. æå–ä¸­æ–‡å…³é”®è¯
        chinese_keywords = self._extract_chinese_keywords(kp_lower)
        extracted_keywords.extend(chinese_keywords)
        
        # 3. æå–è‹±æ–‡å…³é”®è¯
        english_keywords = self._extract_english_keywords(kp_lower)
        extracted_keywords.extend(english_keywords)
        
        # å»é‡å¹¶è¿”å›
        return list(set(extracted_keywords))

    def _extract_chinese_keywords(self, text: str) -> List[str]:
        """
        ğŸ†• æå–ä¸­æ–‡å…³é”®è¯
        """
        chinese_keywords = []
        
        # å®šä¹‰ä¸­æ–‡å…³é”®è¯åˆ—è¡¨
        chinese_keyword_list = [
            'æ¦‚ç‡', 'éšæœº', 'æœŸæœ›', 'ç»Ÿè®¡', 'æ•°æ®', 'åˆ†å¸ƒ',
            'å‡ ä½•', 'å›¾å½¢', 'é¢ç§¯', 'å‘¨é•¿', 'ä½“ç§¯', 'ä¸‰è§’å½¢', 'åœ†å½¢', 'æ­£æ–¹å½¢', 'çŸ©å½¢',
            'ä»£æ•°', 'å‡½æ•°', 'æ–¹ç¨‹', 'ä¸ç­‰å¼', 'å¤šé¡¹å¼', 'æ•°åˆ—', 'å¯¹æ•°', 'æŒ‡æ•°',
            'æ•°è®º', 'æ•´é™¤', 'æ¨¡è¿ç®—', 'å› æ•°', 'è´¨æ•°', 'åˆæ•°', 'è¿›åˆ¶', 'æ•°å­—',
            'è®¡æ•°', 'æ’åˆ—', 'ç»„åˆ', 'é€’å½’', 'é€»è¾‘', 'æ¸¸æˆ', 'ç­–ç•¥',
            'é›†åˆ', 'é›†åˆè®º', 'å…ƒç´ ', 'å­é›†', 'å¹¶é›†', 'äº¤é›†', 'è¡¥é›†'
        ]
        
        for keyword in chinese_keyword_list:
            if keyword in text:
                chinese_keywords.append(keyword)
        
        return chinese_keywords

    def _extract_english_keywords(self, text: str) -> List[str]:
        """
        ğŸ†• æå–è‹±æ–‡å…³é”®è¯
        """
        english_keywords = []
        
        # å®šä¹‰è‹±æ–‡å…³é”®è¯åˆ—è¡¨
        english_keyword_list = [
            'probability', 'random', 'expectation', 'statistics', 'data', 'distribution',
            'geometry', 'triangle', 'circle', 'area', 'perimeter', 'volume',
            'algebra', 'function', 'equation', 'polynomial', 'sequence', 'logarithm', 'exponent',
            'divisibility', 'modulo', 'factor', 'prime', 'composite', 'base', 'digit',
            'counting', 'permutation', 'combination', 'recursion', 'logic', 'game', 'strategy',
            'set', 'set theory', 'element', 'subset', 'union', 'intersection', 'complement'
        ]
        
        for keyword in english_keyword_list:
            if keyword in text:
                english_keywords.append(keyword)
        
        return english_keywords

    def _calculate_keyword_match_score(self, extracted_keywords: List[str], 
                                     question_topic: str, question_division: str, 
                                     question_text: str) -> float:
        """
        ğŸ†• è®¡ç®—å…³é”®è¯åŒ¹é…åˆ†æ•°
        """
        score = 0.0
        
        # 1. TopicåŒ¹é…ï¼ˆæƒé‡æœ€é«˜ï¼‰
        for keyword in extracted_keywords:
            if keyword.lower() in question_topic:
                score += 10.0  # TopicåŒ¹é…å¾—10åˆ†
        
        # 2. DivisionåŒ¹é…ï¼ˆæƒé‡ä¸­ç­‰ï¼‰
        for keyword in extracted_keywords:
            if keyword.lower() in question_division:
                score += 5.0  # DivisionåŒ¹é…å¾—5åˆ†
        
        # 3. é¢˜ç›®æ–‡æœ¬åŒ¹é…ï¼ˆæƒé‡è¾ƒä½ï¼‰
        for keyword in extracted_keywords:
            if keyword.lower() in question_text.lower():
                score += 2.0  # æ–‡æœ¬åŒ¹é…å¾—2åˆ†
        
        # 4. æ‰©å±•å…³é”®è¯åŒ¹é…
        for keyword in extracted_keywords:
            if keyword in self.extended_keyword_mapping:
                for extended_keyword in self.extended_keyword_mapping[keyword]:
                    if extended_keyword.lower() in question_topic.lower():
                        score += 8.0  # æ‰©å±•å…³é”®è¯TopicåŒ¹é…å¾—8åˆ†
                    if extended_keyword.lower() in question_text.lower():
                        score += 3.0  # æ‰©å±•å…³é”®è¯æ–‡æœ¬åŒ¹é…å¾—3åˆ†
        
        return score

    def _get_matched_keywords(self, extracted_keywords: List[str], 
                            question_topic: str, question_division: str, 
                            question_text: str) -> List[str]:
        """
        ğŸ†• è·å–åŒ¹é…çš„å…³é”®è¯åˆ—è¡¨
        """
        matched_keywords = []
        
        for keyword in extracted_keywords:
            if (keyword.lower() in question_topic.lower() or 
                keyword.lower() in question_division.lower() or 
                keyword.lower() in question_text.lower()):
                matched_keywords.append(keyword)
        
        return matched_keywords

    def match_by_topic_code(self, knowledge_point: str, questions_data: List[Dict]) -> List[Dict]:
        """
        UPDATED: åŒ¹é…é€»è¾‘æ›´æ–°ï¼Œä»¥ä½¿ç”¨åŠ¨æ€åŠ è½½çš„å…³é”®è¯å’Œæ–°çš„åŒ¹é…åˆ†æ•°è®¡ç®—ã€‚
        """
        # 1. é¢„æµ‹çŸ¥è¯†ç‚¹çš„topic_code (ä¾‹å¦‚ 'C01', 'G03')
        predicted_codes = self._predict_topic_codes(knowledge_point)
        
        if not predicted_codes:
            print(f"âš ï¸ å¯¹äºçŸ¥è¯†ç‚¹ '{knowledge_point[:30]}...'ï¼Œæœªèƒ½é¢„æµ‹å‡ºä»»ä½•topic codeã€‚")
            return []

        # 2. ä»CSVä¸­ç­›é€‰åŒ¹é…çš„é¢˜ç›®
        matches = []
        for question in questions_data:
            # UPDATED: ä»é¢˜åº“çš„ 'Topic' åˆ—è·å–è¯¥é¢˜ç›®çš„ä»£ç 
            question_topic_code = question.get('Topic')
            
            if not question_topic_code or pd.isna(question_topic_code):
                continue

            # 3. è®¡ç®—åŒ¹é…åˆ†æ•°
            match_score = self._calculate_topic_match_score(predicted_codes, str(question_topic_code))
            
            if match_score > 0:
                question_with_score = question.copy()
                question_with_score['match_score'] = match_score
                question_with_score['predicted_codes_for_kp'] = predicted_codes
                matches.append(question_with_score)
        
        matches.sort(key=lambda x: x['match_score'], reverse=True)
        return matches

    def _predict_topic_codes(self, knowledge_point: str) -> List[str]:
        """
        UPDATED: é¢„æµ‹é€»è¾‘ç°åœ¨ä½¿ç”¨ä»CSVåŠ è½½çš„åŠ¨æ€å…³é”®è¯åº“ã€‚
        """
        kp_lower = knowledge_point.lower()
        predicted = []
        
        # éå†ä» mapping.csv åŠ è½½çš„æ‰€æœ‰çŸ¥è¯†ç‚¹
        for topic_code, keywords in self.topic_keywords.items():
            if any(keyword.lower() in kp_lower for keyword in keywords):
                predicted.append(topic_code)
        
        return predicted

    def _calculate_topic_match_score(self, predicted_codes: List[str], 
                                   question_topic_code: str) -> float:
        """
        UPDATED: åˆ†æ•°è®¡ç®—é€»è¾‘æ›´æ–°ã€‚
        å¦‚æœé¢˜ç›®çš„topic codeåœ¨æˆ‘ä»¬ä¸ºçŸ¥è¯†ç‚¹é¢„æµ‹å‡ºçš„codeåˆ—è¡¨é‡Œï¼Œå°±è®¤ä¸ºåŒ¹é…ã€‚
        """
        if question_topic_code in predicted_codes:
            # å¯ä»¥æ ¹æ®éœ€è¦è®¾è®¡æ›´å¤æ‚çš„åˆ†æ•°ï¼Œç›®å‰åŒ¹é…ä¸Šå³ç»™1åˆ†
            return 1.0 
        return 0.0

# ---------------- ^^^^ NEW CSVMatcher Class ^^^^ ----------------

class QuestionMatcher:
    """é¢˜ç›®åŒ¹é…å™¨"""
    
    def __init__(self):
        self.questions_cache = None
        # ğŸ†• æ–°å¢ï¼šCSVåŒ¹é…å™¨å®ä¾‹
        self.csv_matcher = CSVMatcher()
        # ğŸ†• æ–°å¢ï¼šCSVåŒ¹é…å™¨å®ä¾‹
        self.csv_matcher = CSVMatcher()
        
    def load_questions(self) -> pd.DataFrame:
        """åŠ è½½é¢˜ç›®æ•°æ®"""
        if self.questions_cache is None:
            # å°è¯•åŠ è½½å¤šä¸ªé¢˜åº“æ–‡ä»¶
            csv_files = [
                'data/questions/pdf_test_questions.csv',
                'data/questions/AMC10_realtest.csv', 
                'data/questions/AMC10_v250722.csv'
            ]
            
            for csv_file in csv_files:
                if os.path.exists(csv_file):
                    try:
                        self.questions_cache = pd.read_csv(csv_file)
                        print(f"âœ… æˆåŠŸåŠ è½½é¢˜åº“: {csv_file} ({len(self.questions_cache)}é“é¢˜)")
                        return self.questions_cache
                    except Exception as e:
                        print(f"âŒ åŠ è½½{csv_file}å¤±è´¥: {e}")
                        continue
            
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„é¢˜åº“æ–‡ä»¶")
            return pd.DataFrame()
        
        return self.questions_cache
    
    def find_questions_by_knowledge_point(self, knowledge_point: str, limit: int = 5) -> List[Dict]:
        """
        ğŸ†• æ–°å¢ï¼šåŸºäºçŸ¥è¯†ç‚¹çš„æ™ºèƒ½åŒ¹é…æ–¹æ³•
        ç»“åˆå…³é”®è¯æå–å’ŒtopicåŒ¹é…ï¼Œæä¾›æ›´å‡†ç¡®çš„é¢˜ç›®æ¨è
        """
        questions_df = self.load_questions()
        if questions_df.empty:
            return []
        
        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        questions_data = questions_df.to_dict('records')
        
        # 1. ä½¿ç”¨æ–°çš„å…³é”®è¯åŒ¹é…æ–¹æ³•
        keyword_matches = self.csv_matcher.match_by_knowledge_point_keywords(knowledge_point, questions_data)
        
        # 2. ä½¿ç”¨åŸæœ‰çš„topic codeåŒ¹é…æ–¹æ³•
        topic_matches = self.csv_matcher.match_by_topic_code(knowledge_point, questions_data)
        
        # 3. åˆå¹¶ç»“æœå¹¶å»é‡
        all_matches = {}
        
        # æ·»åŠ å…³é”®è¯åŒ¹é…ç»“æœ
        for match in keyword_matches:
            problem_id = match.get('Problem ID', '')
            if problem_id not in all_matches:
                all_matches[problem_id] = match
            else:
                # å¦‚æœå·²å­˜åœ¨ï¼Œå–æ›´é«˜çš„åˆ†æ•°
                all_matches[problem_id]['match_score'] = max(
                    all_matches[problem_id]['match_score'], 
                    match['match_score']
                )
        
        # æ·»åŠ topicåŒ¹é…ç»“æœ
        for match in topic_matches:
            problem_id = match.get('Problem ID', '')
            if problem_id not in all_matches:
                all_matches[problem_id] = match
            else:
                # å¦‚æœå·²å­˜åœ¨ï¼Œå–æ›´é«˜çš„åˆ†æ•°
                all_matches[problem_id]['match_score'] = max(
                    all_matches[problem_id]['match_score'], 
                    match['match_score']
                )
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
        final_matches = list(all_matches.values())
        final_matches.sort(key=lambda x: x['match_score'], reverse=True)
        
        # æ·»åŠ åŒ¹é…ä¿¡æ¯
        for match in final_matches:
            match['knowledge_point'] = knowledge_point
            match['match_method'] = 'keyword_and_topic'
            match['relevance_score'] = min(100, match['match_score'] * 10)  # è½¬æ¢ä¸º0-100çš„åˆ†æ•°
        
        return final_matches[:limit]
    
    def find_questions_by_topics(self, predicted_topics: List[str], limit: int = 5) -> List[Dict]:
        """
        æ ¹æ®é¢„æµ‹çš„topic_codesåŒ¹é…é¢˜ç›® - ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆä¼˜å…ˆDivisionå’ŒTopicå­—æ®µï¼‰
        
        Args:
            predicted_topics: é¢„æµ‹çš„çŸ¥è¯†ç‚¹æ ‡ç­¾åˆ—è¡¨
            limit: è¿”å›é¢˜ç›®æ•°é‡é™åˆ¶
            
        Returns:
            List[Dict]: åŒ¹é…çš„é¢˜ç›®åˆ—è¡¨
        """
        questions_df = self.load_questions()
        if questions_df.empty:
            return []
        
        matches = []
        for _, question in questions_df.iterrows():
            # è·å–å…³é”®å­—æ®µ
            question_topic = str(question.get('Topic', '')).lower()
            question_division = str(question.get('Division', '')).lower()
            question_text = str(question.get('é¢˜ç›®', ''))
            
            # ğŸ†• æ”¹è¿›1: ä¼˜å…ˆä½¿ç”¨Divisionå’ŒTopicå­—æ®µåŒ¹é…
            division_score = 0
            topic_score = 0
            
            # DivisionåŒ¹é…ï¼ˆæƒé‡æœ€é«˜ï¼‰
            for predicted_topic in predicted_topics:
                predicted_lower = predicted_topic.lower()
                
                # æ£€æŸ¥Divisionå­—æ®µ
                if predicted_lower in question_division:
                    division_score += 5  # DivisionåŒ¹é…å¾—5åˆ†
                
                # æ£€æŸ¥Topicå­—æ®µ
                if predicted_lower in question_topic:
                    topic_score += 3  # TopicåŒ¹é…å¾—3åˆ†
                
                # ğŸ†• æ”¹è¿›2: æ”¯æŒå¤šTopicåŒ¹é…ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰
                topic_list = [t.strip() for t in question_topic.split(',')]
                for topic in topic_list:
                    if predicted_lower in topic:
                        topic_score += 3
            
            # ğŸ†• æ”¹è¿›3: é¢˜ç›®æ–‡æœ¬å…³é”®è¯åŒ¹é…
            keyword_score = 0
            for predicted_topic in predicted_topics:
                predicted_lower = predicted_topic.lower()
                
                # ğŸ†• æ”¹è¿›ï¼šæ›´é€šç”¨çš„ä¸­æ–‡å…³é”®è¯æ˜ å°„
                keyword_mapping = {
                    # æ¦‚ç‡ç›¸å…³
                    'æ¦‚ç‡': ['probability', 'prob', 'chance', 'random', 'likely', 'unlikely', 'odds'],
                    'ç»Ÿè®¡': ['statistics', 'stat', 'data', 'distribution', 'mean', 'median', 'mode'],
                    
                    # å‡ ä½•ç›¸å…³
                    'å‡ ä½•': ['geometry', 'geometric', 'triangle', 'circle', 'area', 'perimeter', 'volume'],
                    'ä¸‰è§’å½¢': ['triangle', 'trigonometric', 'sine', 'cosine', 'tangent'],
                    'åœ†': ['circle', 'circumference', 'radius', 'diameter', 'arc'],
                    'é¢ç§¯': ['area', 'surface', 'square', 'rectangle'],
                    'å‘¨é•¿': ['perimeter', 'circumference', 'boundary'],
                    'ç›¸ä¼¼': ['similar', 'similarity', 'proportion', 'ratio'],
                    'å…¨ç­‰': ['congruent', 'congruence', 'equal', 'identical'],
                    
                    # ä»£æ•°ç›¸å…³
                    'ä»£æ•°': ['algebra', 'equation', 'polynomial', 'solve', 'factor', 'expression'],
                    'å‡½æ•°': ['function', 'graph', 'domain', 'range', 'f(x)', 'y='],
                    'æ–¹ç¨‹': ['equation', 'solve', 'solution', 'root', 'zero'],
                    'å¤šé¡¹å¼': ['polynomial', 'degree', 'coefficient', 'term'],
                    
                    # æ•°è®ºç›¸å…³
                    'æ•°è®º': ['number theory', 'divisibility', 'prime', 'factor', 'modulo'],
                    'æ•´é™¤': ['divisible', 'divisibility', 'factor', 'multiple', 'divide'],
                    'æ¨¡è¿ç®—': ['modulo', 'mod', 'remainder', 'congruent', 'modular'],
                    'å› æ•°': ['factor', 'divisor', 'multiple', 'prime'],
                    'è´¨æ•°': ['prime', 'prime number', 'composite'],
                    
                    # è®¡æ•°ç›¸å…³
                    'è®¡æ•°': ['count', 'counting', 'arrangement', 'combination'],
                    'ç»„åˆ': ['combination', 'combinatorics', 'permutation', 'arrangement'],
                    'æ’åˆ—': ['permutation', 'arrangement', 'order'],
                    
                    # å…¶ä»–æ•°å­¦æ¦‚å¿µ
                    'é›†åˆ': ['set', 'element', 'subset', 'union', 'intersection'],
                    'é€»è¾‘': ['logic', 'logical', 'if', 'then', 'and', 'or'],
                    'ä¸ç­‰å¼': ['inequality', 'greater than', 'less than', 'â‰¥', 'â‰¤'],
                    'ç»å¯¹å€¼': ['absolute value', '|x|', 'magnitude'],
                    'åˆ†æ•°': ['fraction', 'numerator', 'denominator', 'ratio'],
                    'å°æ•°': ['decimal', 'decimal point', 'tenth', 'hundredth'],
                    'ç™¾åˆ†æ¯”': ['percent', 'percentage', '%', 'hundredth']
                }
                
                # æ£€æŸ¥ä¸­æ–‡å…³é”®è¯æ˜ å°„
                for chinese_keyword, english_keywords in keyword_mapping.items():
                    if chinese_keyword in predicted_lower:
                        for english_keyword in english_keywords:
                            if english_keyword in question_text.lower():
                                keyword_score += 1
                
                # ç›´æ¥è‹±æ–‡å…³é”®è¯åŒ¹é…
                if predicted_lower in question_text.lower():
                    keyword_score += 1
            
            # ğŸ†• æ”¹è¿›4: è®¡ç®—æ€»åˆ†
            total_score = division_score + topic_score + keyword_score
            
            if total_score > 0:
                # ğŸ†• æ”¹è¿›5: è®¡ç®—ç›¸å…³åº¦å’Œéš¾åº¦
                relevance_score = self._calculate_relevance_score(division_score, topic_score, keyword_score)
                difficulty_level = self._analyze_difficulty(str(question.get('Difficulty', 'medium')), total_score)
                practice_priority = self._calculate_practice_priority(relevance_score, difficulty_level)
                difficulty_level = self._analyze_difficulty(question.get('éš¾åº¦', ''), total_score)
                practice_priority = self._calculate_practice_priority(relevance_score, difficulty_level)
                
                matches.append({
                    'Problem ID': question.get('Problem ID', ''),
                    'formatted_title': f"{question.get('å¹´ä»½', '')} {question.get('ç«èµ›ç±»åˆ«', '')} Problem {question.get('é¢˜å·', '')}",
                    'question_text': question_text,
                    'topics': question_topic,
                    'division': question_division,
                    'difficulty': question.get('éš¾åº¦', ''),
                    'total_score': total_score,
                    'division_score': division_score,
                    'topic_score': topic_score,
                    'keyword_score': keyword_score,
                    'expected_match': self._judge_expected_match(question_topic, question_division),
                    # ğŸ†• æ–°å¢å­—æ®µ
                    'relevance_score': relevance_score,  # ç›¸å…³åº¦è¯„åˆ† (0-100)
                    'difficulty_level': difficulty_level,  # éš¾åº¦ç­‰çº§ (1-5)
                    'practice_priority': practice_priority,  # ç»ƒä¹ ä¼˜å…ˆçº§ (1-10)
                    'recommended_order': self._get_recommended_order(relevance_score, difficulty_level),
                    # ğŸ†• æ·»åŠ ç­”æ¡ˆå’Œè§£é‡Šå­—æ®µ
                    'answer': question.get('ç­”æ¡ˆ', ''),
                    'explanation': question.get('è§£é¢˜æ€è·¯', ''),
                    'hint': question.get('æç¤º', ''),
                    # ğŸ†• æ·»åŠ é€‰é¡¹å­—æ®µ
                    'optionA': question.get('é€‰é¡¹A', ''),
                    'optionB': question.get('é€‰é¡¹B', ''),
                    'optionC': question.get('é€‰é¡¹C', ''),
                    'optionD': question.get('é€‰é¡¹D', ''),
                    'optionE': question.get('é€‰é¡¹E', '')
                })
        
        # ğŸ†• æ”¹è¿›6: æ™ºèƒ½æ’åº - ç›¸å…³åº¦æœ€é«˜ä½†éš¾åº¦æœ€ä½ä¼˜å…ˆ
        matches.sort(key=lambda x: (x['relevance_score'], -x['difficulty_level']), reverse=True)
        return matches[:limit]
    
    def _judge_expected_match(self, topic: str, division: str) -> str:
        """æ ¹æ®Topicå’ŒDivisionåˆ¤æ–­é¢„æœŸåŒ¹é…åº¦ - é€šç”¨ç‰ˆæœ¬"""
        topic_lower = topic.lower()
        division_lower = division.lower()
        
        # ğŸ†• æ”¹è¿›ï¼šé€šç”¨åŒ¹é…è§„åˆ™
        # å®šä¹‰Topicå’ŒDivisionçš„å¯¹åº”å…³ç³»
        topic_division_mapping = {
            'prob': 'c',      # æ¦‚ç‡ -> è®¡æ•°
            'geom': 'g',      # å‡ ä½• -> å‡ ä½•
            'div': 's',       # æ•´é™¤ -> æ•°è®º
            'mod': 's',       # æ¨¡è¿ç®— -> æ•°è®º
            'factor': 's',    # å› æ•° -> æ•°è®º
            'count': 'c',     # è®¡æ•° -> è®¡æ•°
            'combinatorics': 'c',  # ç»„åˆ -> è®¡æ•°
            'algebra': 'a',   # ä»£æ•° -> ä»£æ•°
            'function': 'a',  # å‡½æ•° -> ä»£æ•°
            'equation': 'a',  # æ–¹ç¨‹ -> ä»£æ•°
            'triangle': 'g',  # ä¸‰è§’å½¢ -> å‡ ä½•
            'circle': 'g',    # åœ† -> å‡ ä½•
            'area': 'g',      # é¢ç§¯ -> å‡ ä½•
            'perimeter': 'g', # å‘¨é•¿ -> å‡ ä½•
            'similar': 'g',   # ç›¸ä¼¼ -> å‡ ä½•
            'congruent': 'g', # å…¨ç­‰ -> å‡ ä½•
        }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰Topic-DivisionåŒ¹é…
        for topic_keyword, expected_division in topic_division_mapping.items():
            if topic_keyword in topic_lower and division_lower == expected_division:
                return 'HIGH'
        
        # æ£€æŸ¥æ˜¯å¦æœ‰TopicåŒ¹é…ï¼ˆä¸è¦æ±‚Divisionå®Œå…¨åŒ¹é…ï¼‰
        topic_keywords = ['prob', 'geom', 'div', 'mod', 'factor', 'count', 'combinatorics', 
                         'algebra', 'function', 'equation', 'triangle', 'circle', 'area', 
                         'perimeter', 'similar', 'congruent']
        
        for keyword in topic_keywords:
            if keyword in topic_lower:
                return 'MEDIUM'
        
        # å¦‚æœéƒ½æ²¡æœ‰åŒ¹é…ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•Topicå†…å®¹
        if topic_lower.strip() and topic_lower != 'nan':
            return 'LOW'
        else:
            return 'VERY_LOW'
    
    def get_question_statistics(self) -> Dict:
        """è·å–é¢˜åº“ç»Ÿè®¡ä¿¡æ¯"""
        questions_df = self.load_questions()
        if questions_df.empty:
            return {}
        
        stats = {
            'total_questions': len(questions_df),
            'topic_distribution': {}
        }
        
        if 'Topic' in questions_df.columns:
            topic_counts = questions_df['Topic'].value_counts()
            stats['topic_distribution'] = topic_counts.to_dict()
        
        return stats
    
    def _calculate_relevance_score(self, division_score: int, topic_score: int, keyword_score: int) -> float:
        """
        è®¡ç®—é¢˜ç›®ä¸çŸ¥è¯†ç‚¹çš„ç›¸å…³åº¦è¯„åˆ† (0-100)
        
        Args:
            division_score: DivisionåŒ¹é…å¾—åˆ†
            topic_score: TopicåŒ¹é…å¾—åˆ†
            keyword_score: å…³é”®è¯åŒ¹é…å¾—åˆ†
            
        Returns:
            float: ç›¸å…³åº¦è¯„åˆ† (0-100)
        """
        # æƒé‡åˆ†é…
        division_weight = 0.5  # DivisionåŒ¹é…æƒé‡æœ€é«˜
        topic_weight = 0.3     # TopicåŒ¹é…æƒé‡ä¸­ç­‰
        keyword_weight = 0.2   # å…³é”®è¯åŒ¹é…æƒé‡æœ€ä½
        
        # æ ‡å‡†åŒ–å¾—åˆ† (å‡è®¾æœ€å¤§å¯èƒ½å¾—åˆ†)
        max_division_score = 5  # æ¯ä¸ªçŸ¥è¯†ç‚¹æœ€å¤š5åˆ†
        max_topic_score = 3     # æ¯ä¸ªçŸ¥è¯†ç‚¹æœ€å¤š3åˆ†
        max_keyword_score = 2   # æ¯ä¸ªçŸ¥è¯†ç‚¹æœ€å¤š2åˆ†
        
        # è®¡ç®—åŠ æƒç›¸å…³åº¦
        normalized_division = min(division_score / max_division_score, 1.0)
        normalized_topic = min(topic_score / max_topic_score, 1.0)
        normalized_keyword = min(keyword_score / max_keyword_score, 1.0)
        
        relevance_score = (
            normalized_division * division_weight +
            normalized_topic * topic_weight +
            normalized_keyword * keyword_weight
        ) * 100
        
        return round(relevance_score, 1)
    
    def _analyze_difficulty(self, difficulty_code: str, total_score: int) -> int:
        """
        åˆ†æé¢˜ç›®éš¾åº¦ç­‰çº§ (1-5)
        
        Args:
            difficulty_code: éš¾åº¦ä»£ç  (E/M/H)
            total_score: åŒ¹é…æ€»åˆ†
            
        Returns:
            int: éš¾åº¦ç­‰çº§ (1-5)
        """
        # åŸºäºéš¾åº¦ä»£ç çš„åˆå§‹ç­‰çº§
        difficulty_mapping = {
            'E': 1,  # Easy
            'M': 3,  # Medium
            'H': 5   # Hard
        }
        
        base_difficulty = difficulty_mapping.get(difficulty_code.upper(), 3)
        
        # æ ¹æ®åŒ¹é…åˆ†æ•°è°ƒæ•´éš¾åº¦
        # åŒ¹é…åˆ†æ•°è¶Šé«˜ï¼Œè¯´æ˜é¢˜ç›®è¶Šç›¸å…³ï¼Œéš¾åº¦æ„ŸçŸ¥å¯èƒ½é™ä½
        if total_score >= 8:
            adjusted_difficulty = max(1, base_difficulty - 1)
        elif total_score >= 5:
            adjusted_difficulty = base_difficulty
        else:
            adjusted_difficulty = min(5, base_difficulty + 1)
        
        return adjusted_difficulty
    
    def _calculate_practice_priority(self, relevance_score: float, difficulty_level: int) -> int:
        """
        è®¡ç®—ç»ƒä¹ ä¼˜å…ˆçº§ (1-10)
        
        ä¼˜å…ˆçº§ç­–ç•¥ï¼š
        1. ç›¸å…³åº¦é«˜ + éš¾åº¦ä½ = æœ€é«˜ä¼˜å…ˆçº§
        2. ç›¸å…³åº¦é«˜ + éš¾åº¦ä¸­ = é«˜ä¼˜å…ˆçº§
        3. ç›¸å…³åº¦ä¸­ + éš¾åº¦ä½ = ä¸­é«˜ä¼˜å…ˆçº§
        4. ç›¸å…³åº¦ä¸­ + éš¾åº¦ä¸­ = ä¸­ä¼˜å…ˆçº§
        5. ç›¸å…³åº¦ä½ + éš¾åº¦ä½ = ä¸­ä½ä¼˜å…ˆçº§
        6. å…¶ä»– = ä½ä¼˜å…ˆçº§
        
        Args:
            relevance_score: ç›¸å…³åº¦è¯„åˆ† (0-100)
            difficulty_level: éš¾åº¦ç­‰çº§ (1-5)
            
        Returns:
            int: ç»ƒä¹ ä¼˜å…ˆçº§ (1-10)
        """
        # ç›¸å…³åº¦ç­‰çº§
        if relevance_score >= 80:
            relevance_level = 3  # é«˜ç›¸å…³åº¦
        elif relevance_score >= 50:
            relevance_level = 2  # ä¸­ç›¸å…³åº¦
        else:
            relevance_level = 1  # ä½ç›¸å…³åº¦
        
        # éš¾åº¦ç­‰çº§
        if difficulty_level <= 2:
            difficulty_level_score = 3  # ä½éš¾åº¦
        elif difficulty_level <= 3:
            difficulty_level_score = 2  # ä¸­éš¾åº¦
        else:
            difficulty_level_score = 1  # é«˜éš¾åº¦
        
        # è®¡ç®—ä¼˜å…ˆçº§
        priority = relevance_level * difficulty_level_score
        
        # ç¡®ä¿ä¼˜å…ˆçº§åœ¨1-10èŒƒå›´å†…
        return max(1, min(10, priority))
    
    def _get_recommended_order(self, relevance_score: float, difficulty_level: int) -> str:
        """
        è·å–æ¨èç»ƒä¹ é¡ºåºæè¿°
        
        Args:
            relevance_score: ç›¸å…³åº¦è¯„åˆ†
            difficulty_level: éš¾åº¦ç­‰çº§
            
        Returns:
            str: æ¨èé¡ºåºæè¿°
        """
        if relevance_score >= 80 and difficulty_level <= 2:
            return "ä¼˜å…ˆç»ƒä¹  - é«˜ç›¸å…³åº¦ä½éš¾åº¦"
        elif relevance_score >= 60 and difficulty_level <= 3:
            return "æ¨èç»ƒä¹  - ä¸­é«˜ç›¸å…³åº¦é€‚ä¸­éš¾åº¦"
        elif relevance_score >= 40:
            return "å¯é€‰ç»ƒä¹  - ä¸­ç­‰ç›¸å…³åº¦"
        else:
            return "å¤‡é€‰ç»ƒä¹  - ç›¸å…³åº¦è¾ƒä½"
    
    def get_practice_recommendations(self, knowledge_point: str, limit: int = 10) -> Dict:
        """
        è·å–ç»ƒä¹ æ¨èåˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        
        Args:
            knowledge_point: çŸ¥è¯†ç‚¹åç§°
            limit: æ¨èé¢˜ç›®æ•°é‡
            
        Returns:
            Dict: ç»ƒä¹ æ¨èç»“æœ
        """
        # ğŸ†• ä½¿ç”¨æ–°çš„åŸºäºçŸ¥è¯†ç‚¹çš„åŒ¹é…æ–¹æ³•
        matched_questions = self.find_questions_by_knowledge_point(knowledge_point, limit * 2)
        
        # æŒ‰ç»ƒä¹ ä¼˜å…ˆçº§æ’åº
        matched_questions.sort(key=lambda x: x.get('practice_priority', 0), reverse=True)
        
        # åˆ†ç±»æ¨è
        recommendations = {
            'priority_1': [],  # æœ€é«˜ä¼˜å…ˆçº§
            'priority_2': [],  # é«˜ä¼˜å…ˆçº§
            'priority_3': [],  # ä¸­ä¼˜å…ˆçº§
            'priority_4': []   # ä½ä¼˜å…ˆçº§
        }
        
        for question in matched_questions[:limit]:
            priority = question.get('practice_priority', 0)
            
            if priority >= 8:
                recommendations['priority_1'].append(question)
            elif priority >= 6:
                recommendations['priority_2'].append(question)
            elif priority >= 4:
                recommendations['priority_3'].append(question)
            else:
                recommendations['priority_4'].append(question)
        
        return {
            'knowledge_point': knowledge_point,
            'total_matched': len(matched_questions),
            'recommendations': recommendations,
            'practice_strategy': self._generate_practice_strategy(recommendations)
        }
    
    def _generate_practice_strategy(self, recommendations: Dict) -> str:
        """
        ç”Ÿæˆç»ƒä¹ ç­–ç•¥å»ºè®®
        
        Args:
            recommendations: æ¨èç»“æœ
            
        Returns:
            str: ç»ƒä¹ ç­–ç•¥
        """
        strategy = "ğŸ“š ç»ƒä¹ ç­–ç•¥å»ºè®®:\n"
        
        if recommendations['priority_1']:
            strategy += f"ğŸ¯ ä¼˜å…ˆç»ƒä¹  ({len(recommendations['priority_1'])}é¢˜): é«˜ç›¸å…³åº¦ä½éš¾åº¦ï¼Œé€‚åˆå…¥é—¨\n"
        
        if recommendations['priority_2']:
            strategy += f"ğŸ“ˆ è¿›é˜¶ç»ƒä¹  ({len(recommendations['priority_2'])}é¢˜): ä¸­é«˜ç›¸å…³åº¦é€‚ä¸­éš¾åº¦ï¼Œå·©å›ºåŸºç¡€\n"
        
        if recommendations['priority_3']:
            strategy += f"ğŸ” æ‹“å±•ç»ƒä¹  ({len(recommendations['priority_3'])}é¢˜): ä¸­ç­‰ç›¸å…³åº¦ï¼Œæ‰©å±•çŸ¥è¯†é¢\n"
        
        if recommendations['priority_4']:
            strategy += f"ğŸ’¡ æŒ‘æˆ˜ç»ƒä¹  ({len(recommendations['priority_4'])}é¢˜): ç›¸å…³åº¦è¾ƒä½ä½†å¯å°è¯•\n"
        
        return strategy 