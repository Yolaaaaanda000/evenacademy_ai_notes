import google.generativeai as genai
from typing import Dict

class PracticeLLMHandler:
    """
    è´Ÿè´£å¤„ç†ç»ƒä¹ å¯¹è¯æ¡†ä¸­çš„LLMäº¤äº’ã€‚
    åŒ…æ‹¬åŠ è½½promptæ¨¡æ¿ã€ä¸Gemini APIé€šä¿¡ç­‰ã€‚
    """
    def __init__(self, prompt_template_path: str):
        """
        åˆå§‹åŒ–å¤„ç†å™¨ï¼ŒåŠ è½½promptæ¨¡æ¿ã€‚
        """
        self.prompt_template = self._load_prompt_template(prompt_template_path)
        self.model = genai.GenerativeModel('models/gemini-2.5-pro')

    def _load_prompt_template(self, filepath: str) -> str:
        """
        ä»æ–‡ä»¶åŠ è½½promptæ¨¡æ¿ã€‚
        """
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            print(f"âŒ é”™è¯¯: Promptæ¨¡æ¿æ–‡ä»¶æœªæ‰¾åˆ° at {filepath}")
            return "é”™è¯¯ï¼šæ— æ³•åŠ è½½Promptæ¨¡æ¿ã€‚"
        except Exception as e:
            print(f"âŒ é”™è¯¯: è¯»å–Promptæ¨¡æ¿æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return "é”™è¯¯ï¼šæ— æ³•åŠ è½½Promptæ¨¡æ¿ã€‚"

    def generate_response(self, knowledge_point: str, question: Dict, user_message: str, language: str = 'ä¸­æ–‡') -> str:
        """
        æ ¹æ®é¢˜ç›®ä¿¡æ¯å’Œç”¨æˆ·æ¶ˆæ¯ï¼Œç”ŸæˆLLMçš„å›å¤ã€‚
        
        Args:
            knowledge_point: çŸ¥è¯†ç‚¹åç§°
            question: é¢˜ç›®ä¿¡æ¯å­—å…¸
            user_message: ç”¨æˆ·æ¶ˆæ¯
            language: å›å¤è¯­è¨€ï¼Œé»˜è®¤ä¸ºä¸­æ–‡
        """
        if "é”™è¯¯" in self.prompt_template:
            return self.prompt_template

        try:
            # å‡†å¤‡å¡«å……æ¨¡æ¿æ‰€éœ€çš„æ•°æ®
            prompt_data = {
                'knowledge_point': knowledge_point,
                'title': question.get('title', ''),
                'question_text': question.get('question_text', ''),
                'optionA': question.get('optionA', ''),
                'optionB': question.get('optionB', ''),
                'optionC': question.get('optionC', ''),
                'optionD': question.get('optionD', ''),
                'optionE': question.get('optionE', ''),
                'answer': question.get('answer', 'N/A'),
                'explanation': question.get('explanation', 'N/A'),
                'user_message': user_message,
                'language': language
            }
            
            # ä½¿ç”¨.format()æ–¹æ³•å¡«å……æ¨¡æ¿
            final_prompt = self.prompt_template.format(**prompt_data)
            
            # è°ƒç”¨Geminiæ¨¡å‹
            response = self.model.generate_content(final_prompt)
            
            # ğŸ†• ä¿®å¤Gemini APIå“åº”æ ¼å¼é—®é¢˜
            if hasattr(response, 'text'):
                return response.text
            elif hasattr(response, 'parts') and response.parts:
                return response.parts[0].text
            elif hasattr(response, 'candidates') and response.candidates:
                return response.candidates[0].content.parts[0].text
            else:
                return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚"

        except Exception as e:
            print(f"âŒ è°ƒç”¨LLMç”Ÿæˆå›å¤æ—¶å‡ºé”™: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ã€‚"